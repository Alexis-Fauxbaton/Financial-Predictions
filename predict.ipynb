{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BTC-USD_SIGNALS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>Confirmation Time</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Miners Revenue</th>\n",
       "      <th>FnG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>10237.299805</td>\n",
       "      <td>10288.799805</td>\n",
       "      <td>8812.280273</td>\n",
       "      <td>9170.540039</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-2.712213</td>\n",
       "      <td>-1.043523</td>\n",
       "      <td>-1.108359</td>\n",
       "      <td>-0.475907</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.583209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>9142.280273</td>\n",
       "      <td>9142.280273</td>\n",
       "      <td>7796.490234</td>\n",
       "      <td>8830.750000</td>\n",
       "      <td>-0.152676</td>\n",
       "      <td>-1.011481</td>\n",
       "      <td>-1.204172</td>\n",
       "      <td>-1.202571</td>\n",
       "      <td>-0.654534</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-1.244407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>8852.120117</td>\n",
       "      <td>9430.750000</td>\n",
       "      <td>8251.629883</td>\n",
       "      <td>9174.910156</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>9175.700195</td>\n",
       "      <td>9334.870117</td>\n",
       "      <td>8031.220215</td>\n",
       "      <td>8277.009766</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>8270.540039</td>\n",
       "      <td>8364.839844</td>\n",
       "      <td>6756.680176</td>\n",
       "      <td>6955.270020</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>19832.470703</td>\n",
       "      <td>19999.689453</td>\n",
       "      <td>19636.816406</td>\n",
       "      <td>19986.712891</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>-1.113287</td>\n",
       "      <td>-0.844382</td>\n",
       "      <td>-0.254845</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-1.024008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>19988.789063</td>\n",
       "      <td>20031.160156</td>\n",
       "      <td>19673.046875</td>\n",
       "      <td>19812.371094</td>\n",
       "      <td>0.658018</td>\n",
       "      <td>-0.278482</td>\n",
       "      <td>-1.133325</td>\n",
       "      <td>-0.831832</td>\n",
       "      <td>-0.166540</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.891768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>19817.724609</td>\n",
       "      <td>20155.269531</td>\n",
       "      <td>18800.171875</td>\n",
       "      <td>18837.667969</td>\n",
       "      <td>1.393318</td>\n",
       "      <td>-1.325705</td>\n",
       "      <td>-1.548973</td>\n",
       "      <td>-0.892284</td>\n",
       "      <td>-0.308652</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-0.935848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>18837.683594</td>\n",
       "      <td>19427.171875</td>\n",
       "      <td>18644.466797</td>\n",
       "      <td>19290.324219</td>\n",
       "      <td>0.981876</td>\n",
       "      <td>0.568952</td>\n",
       "      <td>-1.180050</td>\n",
       "      <td>-0.893278</td>\n",
       "      <td>-0.249058</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-0.847688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>19289.941406</td>\n",
       "      <td>19417.351563</td>\n",
       "      <td>19076.714844</td>\n",
       "      <td>19329.833984</td>\n",
       "      <td>0.828407</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-1.279608</td>\n",
       "      <td>-0.881242</td>\n",
       "      <td>-0.163410</td>\n",
       "      <td>-0.653287</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-1.024008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2018-02-01  10237.299805  10288.799805   8812.280273   9170.540039   \n",
       "1     2018-02-02   9142.280273   9142.280273   7796.490234   8830.750000   \n",
       "2     2018-02-03   8852.120117   9430.750000   8251.629883   9174.910156   \n",
       "3     2018-02-04   9175.700195   9334.870117   8031.220215   8277.009766   \n",
       "4     2018-02-05   8270.540039   8364.839844   6756.680176   6955.270020   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "1679  2022-09-04  19832.470703  19999.689453  19636.816406  19986.712891   \n",
       "1680  2022-09-05  19988.789063  20031.160156  19673.046875  19812.371094   \n",
       "1681  2022-09-06  19817.724609  20155.269531  18800.171875  18837.667969   \n",
       "1682  2022-09-07  18837.683594  19427.171875  18644.466797  19290.324219   \n",
       "1683  2022-09-08  19289.941406  19417.351563  19076.714844  19329.833984   \n",
       "\n",
       "        Volume  Variation       RSI      MACD    MACD_H  Confirmation Time  \\\n",
       "0    -0.292146  -2.712213 -1.043523 -1.108359 -0.475907           1.144750   \n",
       "1    -0.152676  -1.011481 -1.204172 -1.202571 -0.654534           1.144750   \n",
       "2    -0.427993   0.955604 -1.632900 -1.235294 -0.618233           1.114249   \n",
       "3    -0.437581  -2.584947 -1.626830 -1.320379 -0.741794           1.114249   \n",
       "4    -0.326118  -4.184569 -1.814295 -1.479953 -1.057732           1.114249   \n",
       "...        ...        ...       ...       ...       ...                ...   \n",
       "1679  0.478227   0.148948 -1.113287 -0.844382 -0.254845          -1.063067   \n",
       "1680  0.658018  -0.278482 -1.133325 -0.831832 -0.166540          -0.742360   \n",
       "1681  1.393318  -1.325705 -1.548973 -0.892284 -0.308652          -0.742360   \n",
       "1682  0.981876   0.568952 -1.180050 -0.893278 -0.249058          -0.742360   \n",
       "1683  0.828407   0.000209 -1.279608 -0.881242 -0.163410          -0.653287   \n",
       "\n",
       "      Transactions  Miners Revenue       FnG  \n",
       "0        -0.774692       -0.186892 -0.583209  \n",
       "1        -0.774692       -0.186892 -1.244407  \n",
       "2        -0.774692       -0.186892 -0.142410  \n",
       "3        -1.144752       -0.264496 -0.847688  \n",
       "4        -1.144752       -0.264496 -1.420727  \n",
       "...            ...             ...       ...  \n",
       "1679     -0.648298       -0.307825 -1.024008  \n",
       "1680     -0.648298       -0.307825 -0.891768  \n",
       "1681     -0.165203       -0.359746 -0.935848  \n",
       "1682     -0.165203       -0.359746 -0.847688  \n",
       "1683     -0.165203       -0.359746 -1.024008  \n",
       "\n",
       "[1684 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = data.copy().drop([\"Open\",\"Close\",\"High\",\"Low\"],axis=1)\n",
    "max_days = 5\n",
    "target_range = 2\n",
    "for i in range(1,max_days):#2jours\n",
    "    predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\"]].shift(i)\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\"]].shift(i)\n",
    "#predict_data[\"Target\"] = (data[\"Variation\"].shift(-1) >= 0)\n",
    "predict_data[\"Target\"] = (data[\"Close\"].shift(-target_range) - data[\"Close\"] >= 0)\n",
    "predict_data[\"Target\"] = np.where(predict_data[\"Target\"] == True, 1, 0)\n",
    "predict_data.dropna(inplace=True)\n",
    "predict_data.reset_index(inplace=True,drop=True)\n",
    "predict_data = predict_data[0:len(predict_data)-target_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = predict_data[[i % int(max_days / 2) == 0 for i in range(len(predict_data))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>Confirmation Time</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Miners Revenue</th>\n",
       "      <th>FnG</th>\n",
       "      <th>...</th>\n",
       "      <th>Variation-4</th>\n",
       "      <th>Vol-4</th>\n",
       "      <th>RSI-4</th>\n",
       "      <th>MACD-4</th>\n",
       "      <th>MACD_H-4</th>\n",
       "      <th>CONF-4</th>\n",
       "      <th>TRANS-4</th>\n",
       "      <th>REV-4</th>\n",
       "      <th>FnG-4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.712213</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-1.043523</td>\n",
       "      <td>-1.108359</td>\n",
       "      <td>-0.475907</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.583209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>-0.495589</td>\n",
       "      <td>-1.457407</td>\n",
       "      <td>-1.552132</td>\n",
       "      <td>-0.860381</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.318730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>-0.452131</td>\n",
       "      <td>1.422827</td>\n",
       "      <td>-0.830140</td>\n",
       "      <td>-1.412981</td>\n",
       "      <td>-0.171285</td>\n",
       "      <td>0.207605</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>-0.485525</td>\n",
       "      <td>-1.529055</td>\n",
       "      <td>-1.178450</td>\n",
       "      <td>-1.298888</td>\n",
       "      <td>0.178688</td>\n",
       "      <td>0.207605</td>\n",
       "      <td>-2.453448</td>\n",
       "      <td>-0.455877</td>\n",
       "      <td>-0.539129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495589</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>-1.457407</td>\n",
       "      <td>-1.552132</td>\n",
       "      <td>-0.860381</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.318730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>-0.506967</td>\n",
       "      <td>-1.004265</td>\n",
       "      <td>-0.584168</td>\n",
       "      <td>-1.121564</td>\n",
       "      <td>0.570097</td>\n",
       "      <td>0.276565</td>\n",
       "      <td>-1.522212</td>\n",
       "      <td>-0.160496</td>\n",
       "      <td>-0.362809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.422827</td>\n",
       "      <td>-0.452131</td>\n",
       "      <td>-0.830140</td>\n",
       "      <td>-1.412981</td>\n",
       "      <td>-0.171285</td>\n",
       "      <td>0.207605</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>0.433926</td>\n",
       "      <td>-0.601366</td>\n",
       "      <td>-2.100264</td>\n",
       "      <td>-0.799658</td>\n",
       "      <td>-1.290428</td>\n",
       "      <td>-1.263537</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.671369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212717</td>\n",
       "      <td>0.816704</td>\n",
       "      <td>-1.545836</td>\n",
       "      <td>-0.444016</td>\n",
       "      <td>-1.152727</td>\n",
       "      <td>-1.025714</td>\n",
       "      <td>-0.498097</td>\n",
       "      <td>-0.206563</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>0.943757</td>\n",
       "      <td>-0.691652</td>\n",
       "      <td>-1.653641</td>\n",
       "      <td>-0.871357</td>\n",
       "      <td>-1.020465</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.715449</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.658930</td>\n",
       "      <td>1.339033</td>\n",
       "      <td>-2.000380</td>\n",
       "      <td>-0.584031</td>\n",
       "      <td>-1.132733</td>\n",
       "      <td>-1.025714</td>\n",
       "      <td>-0.310257</td>\n",
       "      <td>-0.097684</td>\n",
       "      <td>-0.715449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601366</td>\n",
       "      <td>0.433926</td>\n",
       "      <td>-2.100264</td>\n",
       "      <td>-0.799658</td>\n",
       "      <td>-1.290428</td>\n",
       "      <td>-1.263537</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.671369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>0.395940</td>\n",
       "      <td>-0.231177</td>\n",
       "      <td>-0.964656</td>\n",
       "      <td>-0.866931</td>\n",
       "      <td>-0.401653</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.979928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691652</td>\n",
       "      <td>0.943757</td>\n",
       "      <td>-1.653641</td>\n",
       "      <td>-0.871357</td>\n",
       "      <td>-1.020465</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.715449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>0.658018</td>\n",
       "      <td>-0.278482</td>\n",
       "      <td>-1.133325</td>\n",
       "      <td>-0.831832</td>\n",
       "      <td>-0.166540</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Volume  Variation       RSI      MACD    MACD_H  \\\n",
       "0     2018-02-05 -0.326118  -4.184569 -1.814295 -1.479953 -1.057732   \n",
       "2     2018-02-07 -0.331965  -0.495589 -1.457407 -1.552132 -0.860381   \n",
       "4     2018-02-09 -0.452131   1.422827 -0.830140 -1.412981 -0.171285   \n",
       "6     2018-02-11 -0.485525  -1.529055 -1.178450 -1.298888  0.178688   \n",
       "8     2018-02-13 -0.506967  -1.004265 -0.584168 -1.121564  0.570097   \n",
       "...          ...       ...        ...       ...       ...       ...   \n",
       "1668  2022-08-28  0.433926  -0.601366 -2.100264 -0.799658 -1.290428   \n",
       "1670  2022-08-30  0.943757  -0.691652 -1.653641 -0.871357 -1.020465   \n",
       "1672  2022-09-01  0.726988   0.047069 -1.336325 -0.871305 -0.646449   \n",
       "1674  2022-09-03  0.395940  -0.231177 -0.964656 -0.866931 -0.401653   \n",
       "1676  2022-09-05  0.658018  -0.278482 -1.133325 -0.831832 -0.166540   \n",
       "\n",
       "      Confirmation Time  Transactions  Miners Revenue       FnG  ...  \\\n",
       "0              1.114249     -1.144752       -0.264496 -1.420727  ...   \n",
       "2              0.453384     -1.959889       -0.596734 -0.318730  ...   \n",
       "4              0.207605     -1.959889       -0.596734  0.033910  ...   \n",
       "6              0.207605     -2.453448       -0.455877 -0.539129  ...   \n",
       "8              0.276565     -1.522212       -0.160496 -0.362809  ...   \n",
       "...                 ...           ...             ...       ...  ...   \n",
       "1668          -1.263537     -1.414496       -0.174982 -0.671369  ...   \n",
       "1670          -1.313931     -1.414496       -0.174982 -0.715449  ...   \n",
       "1672          -1.313931     -0.310919       -0.277036 -1.024008  ...   \n",
       "1674          -1.063067     -0.648298       -0.307825 -0.979928  ...   \n",
       "1676          -0.742360     -0.648298       -0.307825 -0.891768  ...   \n",
       "\n",
       "      Variation-4     Vol-4     RSI-4    MACD-4  MACD_H-4    CONF-4   TRANS-4  \\\n",
       "0       -2.712213 -0.292146 -1.043523 -1.108359 -0.475907  1.144750 -0.774692   \n",
       "2        0.955604 -0.427993 -1.632900 -1.235294 -0.618233  1.114249 -0.774692   \n",
       "4       -4.184569 -0.326118 -1.814295 -1.479953 -1.057732  1.114249 -1.144752   \n",
       "6       -0.495589 -0.331965 -1.457407 -1.552132 -0.860381  0.453384 -1.959889   \n",
       "8        1.422827 -0.452131 -0.830140 -1.412981 -0.171285  0.207605 -1.959889   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1668    -0.212717  0.816704 -1.545836 -0.444016 -1.152727 -1.025714 -0.498097   \n",
       "1670    -1.658930  1.339033 -2.000380 -0.584031 -1.132733 -1.025714 -0.310257   \n",
       "1672    -0.601366  0.433926 -2.100264 -0.799658 -1.290428 -1.263537 -1.414496   \n",
       "1674    -0.691652  0.943757 -1.653641 -0.871357 -1.020465 -1.313931 -1.414496   \n",
       "1676     0.047069  0.726988 -1.336325 -0.871305 -0.646449 -1.313931 -0.310919   \n",
       "\n",
       "         REV-4     FnG-4  Target  \n",
       "0    -0.186892 -0.583209       1  \n",
       "2    -0.186892 -0.142410       1  \n",
       "4    -0.264496 -1.420727       0  \n",
       "6    -0.596734 -0.318730       1  \n",
       "8    -0.596734  0.033910       1  \n",
       "...        ...       ...     ...  \n",
       "1668 -0.206563 -0.803608       1  \n",
       "1670 -0.097684 -0.715449       1  \n",
       "1672 -0.174982 -0.671369       0  \n",
       "1674 -0.174982 -0.715449       0  \n",
       "1676 -0.277036 -1.024008       0  \n",
       "\n",
       "[839 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = predict_data.corr(\"pearson\")\n",
    "#corr[[\"Target\"]].to_clipboard()\n",
    "#corr[[\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mode = \"RAND\"\n",
    "\n",
    "if split_mode == \"RAND\":\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\",\"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=100)\n",
    "elif split_mode == \"STATIC\":\n",
    "    train_data = predict_data[0:int(0.66*len(predict_data))].drop([\"Date\",\"Target\"],axis=1)\n",
    "    train_labels = predict_data[0:int(0.66*len(predict_data))][\"Target\"]\n",
    "    test_data = predict_data[int(0.66*len(predict_data)):len(predict_data)].drop([\"Date\",\"Target\"],axis=1)\n",
    "    test_labels = predict_data[int(0.66*len(predict_data)):len(predict_data)][\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.066538\n",
      "0:\tlearn: 0.6638149\ttotal: 1.29s\tremaining: 2m 7s\n",
      "1:\tlearn: 0.6414676\ttotal: 2.23s\tremaining: 1m 49s\n",
      "2:\tlearn: 0.6176488\ttotal: 3.13s\tremaining: 1m 41s\n",
      "3:\tlearn: 0.5951911\ttotal: 3.98s\tremaining: 1m 35s\n",
      "4:\tlearn: 0.5793617\ttotal: 5.06s\tremaining: 1m 36s\n",
      "5:\tlearn: 0.5622152\ttotal: 6.24s\tremaining: 1m 37s\n",
      "6:\tlearn: 0.5485485\ttotal: 7.42s\tremaining: 1m 38s\n",
      "7:\tlearn: 0.5317194\ttotal: 8.53s\tremaining: 1m 38s\n",
      "8:\tlearn: 0.5157837\ttotal: 9.62s\tremaining: 1m 37s\n",
      "9:\tlearn: 0.5025932\ttotal: 10.6s\tremaining: 1m 34s\n",
      "10:\tlearn: 0.4860133\ttotal: 11.4s\tremaining: 1m 32s\n",
      "11:\tlearn: 0.4742485\ttotal: 12.2s\tremaining: 1m 29s\n",
      "12:\tlearn: 0.4644863\ttotal: 13.1s\tremaining: 1m 27s\n",
      "13:\tlearn: 0.4503247\ttotal: 14s\tremaining: 1m 26s\n",
      "14:\tlearn: 0.4377393\ttotal: 14.9s\tremaining: 1m 24s\n",
      "15:\tlearn: 0.4247406\ttotal: 15.9s\tremaining: 1m 23s\n",
      "16:\tlearn: 0.4119508\ttotal: 16.8s\tremaining: 1m 22s\n",
      "17:\tlearn: 0.4030521\ttotal: 17.8s\tremaining: 1m 21s\n",
      "18:\tlearn: 0.3962178\ttotal: 18.8s\tremaining: 1m 20s\n",
      "19:\tlearn: 0.3863776\ttotal: 19.9s\tremaining: 1m 19s\n",
      "20:\tlearn: 0.3775030\ttotal: 20.9s\tremaining: 1m 18s\n",
      "21:\tlearn: 0.3662913\ttotal: 21.9s\tremaining: 1m 17s\n",
      "22:\tlearn: 0.3557819\ttotal: 22.9s\tremaining: 1m 16s\n",
      "23:\tlearn: 0.3483994\ttotal: 23.9s\tremaining: 1m 15s\n",
      "24:\tlearn: 0.3388856\ttotal: 24.9s\tremaining: 1m 14s\n",
      "25:\tlearn: 0.3295253\ttotal: 25.9s\tremaining: 1m 13s\n",
      "26:\tlearn: 0.3225549\ttotal: 27s\tremaining: 1m 12s\n",
      "27:\tlearn: 0.3130304\ttotal: 28s\tremaining: 1m 11s\n",
      "28:\tlearn: 0.3047079\ttotal: 29.1s\tremaining: 1m 11s\n",
      "29:\tlearn: 0.2969595\ttotal: 30.1s\tremaining: 1m 10s\n",
      "30:\tlearn: 0.2882143\ttotal: 31s\tremaining: 1m 9s\n",
      "31:\tlearn: 0.2826492\ttotal: 31.9s\tremaining: 1m 7s\n",
      "32:\tlearn: 0.2756089\ttotal: 32.9s\tremaining: 1m 6s\n",
      "33:\tlearn: 0.2698450\ttotal: 33.9s\tremaining: 1m 5s\n",
      "34:\tlearn: 0.2640671\ttotal: 34.9s\tremaining: 1m 4s\n",
      "35:\tlearn: 0.2585523\ttotal: 36s\tremaining: 1m 3s\n",
      "36:\tlearn: 0.2542019\ttotal: 36.9s\tremaining: 1m 2s\n",
      "37:\tlearn: 0.2484322\ttotal: 37.9s\tremaining: 1m 1s\n",
      "38:\tlearn: 0.2445611\ttotal: 38.8s\tremaining: 1m\n",
      "39:\tlearn: 0.2389962\ttotal: 39.7s\tremaining: 59.6s\n",
      "40:\tlearn: 0.2349171\ttotal: 40.7s\tremaining: 58.5s\n",
      "41:\tlearn: 0.2310667\ttotal: 41.6s\tremaining: 57.4s\n",
      "42:\tlearn: 0.2267381\ttotal: 42.5s\tremaining: 56.3s\n",
      "43:\tlearn: 0.2233333\ttotal: 43.4s\tremaining: 55.2s\n",
      "44:\tlearn: 0.2192589\ttotal: 44.3s\tremaining: 54.1s\n",
      "45:\tlearn: 0.2152769\ttotal: 45.2s\tremaining: 53s\n",
      "46:\tlearn: 0.2114242\ttotal: 46.2s\tremaining: 52.1s\n",
      "47:\tlearn: 0.2075010\ttotal: 47.1s\tremaining: 51.1s\n",
      "48:\tlearn: 0.2039176\ttotal: 48.1s\tremaining: 50s\n",
      "49:\tlearn: 0.2005568\ttotal: 49s\tremaining: 49s\n",
      "50:\tlearn: 0.1985385\ttotal: 50s\tremaining: 48s\n",
      "51:\tlearn: 0.1951220\ttotal: 50.9s\tremaining: 47s\n",
      "52:\tlearn: 0.1924479\ttotal: 51.8s\tremaining: 46s\n",
      "53:\tlearn: 0.1894773\ttotal: 52.8s\tremaining: 45s\n",
      "54:\tlearn: 0.1861148\ttotal: 53.8s\tremaining: 44s\n",
      "55:\tlearn: 0.1827400\ttotal: 54.7s\tremaining: 43s\n",
      "56:\tlearn: 0.1805700\ttotal: 55.7s\tremaining: 42s\n",
      "57:\tlearn: 0.1780618\ttotal: 56.6s\tremaining: 41s\n",
      "58:\tlearn: 0.1749660\ttotal: 57.6s\tremaining: 40s\n",
      "59:\tlearn: 0.1721100\ttotal: 58.5s\tremaining: 39s\n",
      "60:\tlearn: 0.1691438\ttotal: 59.5s\tremaining: 38s\n",
      "61:\tlearn: 0.1666281\ttotal: 1m\tremaining: 37s\n",
      "62:\tlearn: 0.1643692\ttotal: 1m 1s\tremaining: 36s\n",
      "63:\tlearn: 0.1609521\ttotal: 1m 2s\tremaining: 35s\n",
      "64:\tlearn: 0.1588864\ttotal: 1m 3s\tremaining: 34.1s\n",
      "65:\tlearn: 0.1567977\ttotal: 1m 4s\tremaining: 33.1s\n",
      "66:\tlearn: 0.1548203\ttotal: 1m 5s\tremaining: 32.1s\n",
      "67:\tlearn: 0.1521992\ttotal: 1m 6s\tremaining: 31.1s\n",
      "68:\tlearn: 0.1496705\ttotal: 1m 7s\tremaining: 30.2s\n",
      "69:\tlearn: 0.1471772\ttotal: 1m 8s\tremaining: 29.2s\n",
      "70:\tlearn: 0.1450902\ttotal: 1m 9s\tremaining: 28.2s\n",
      "71:\tlearn: 0.1427037\ttotal: 1m 10s\tremaining: 27.2s\n",
      "72:\tlearn: 0.1403802\ttotal: 1m 11s\tremaining: 26.3s\n",
      "73:\tlearn: 0.1377965\ttotal: 1m 11s\tremaining: 25.3s\n",
      "74:\tlearn: 0.1363960\ttotal: 1m 12s\tremaining: 24.3s\n",
      "75:\tlearn: 0.1341953\ttotal: 1m 13s\tremaining: 23.3s\n",
      "76:\tlearn: 0.1316715\ttotal: 1m 14s\tremaining: 22.3s\n",
      "77:\tlearn: 0.1303401\ttotal: 1m 15s\tremaining: 21.3s\n",
      "78:\tlearn: 0.1281305\ttotal: 1m 16s\tremaining: 20.3s\n",
      "79:\tlearn: 0.1262354\ttotal: 1m 17s\tremaining: 19.4s\n",
      "80:\tlearn: 0.1248692\ttotal: 1m 18s\tremaining: 18.4s\n",
      "81:\tlearn: 0.1230911\ttotal: 1m 19s\tremaining: 17.4s\n",
      "82:\tlearn: 0.1210453\ttotal: 1m 20s\tremaining: 16.5s\n",
      "83:\tlearn: 0.1189545\ttotal: 1m 21s\tremaining: 15.5s\n",
      "84:\tlearn: 0.1171723\ttotal: 1m 22s\tremaining: 14.5s\n",
      "85:\tlearn: 0.1154397\ttotal: 1m 23s\tremaining: 13.5s\n",
      "86:\tlearn: 0.1134285\ttotal: 1m 24s\tremaining: 12.6s\n",
      "87:\tlearn: 0.1121366\ttotal: 1m 25s\tremaining: 11.6s\n",
      "88:\tlearn: 0.1105301\ttotal: 1m 26s\tremaining: 10.6s\n",
      "89:\tlearn: 0.1090421\ttotal: 1m 26s\tremaining: 9.66s\n",
      "90:\tlearn: 0.1076964\ttotal: 1m 27s\tremaining: 8.69s\n",
      "91:\tlearn: 0.1063334\ttotal: 1m 28s\tremaining: 7.72s\n",
      "92:\tlearn: 0.1052334\ttotal: 1m 29s\tremaining: 6.76s\n",
      "93:\tlearn: 0.1039366\ttotal: 1m 30s\tremaining: 5.79s\n",
      "94:\tlearn: 0.1023849\ttotal: 1m 31s\tremaining: 4.83s\n",
      "95:\tlearn: 0.1007478\ttotal: 1m 32s\tremaining: 3.86s\n",
      "96:\tlearn: 0.0993481\ttotal: 1m 33s\tremaining: 2.9s\n",
      "97:\tlearn: 0.0981218\ttotal: 1m 34s\tremaining: 1.93s\n",
      "98:\tlearn: 0.0969768\ttotal: 1m 35s\tremaining: 965ms\n",
      "99:\tlearn: 0.0961652\ttotal: 1m 36s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25bbfa05ac0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = \"CAT\"\n",
    "\n",
    "if algo == \"MLP\":\n",
    "    model = MLPClassifier(hidden_layer_sizes=(200,2000,200),verbose=True)\n",
    "elif algo == \"RF\":\n",
    "    model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "elif algo == \"CAT\":\n",
    "    model = CatBoostClassifier(iterations=100,depth=12)\n",
    "elif algo == \"TREE\":\n",
    "    model = DecisionTreeClassifier(splitter=\"random\")\n",
    "model.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595667870036101"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 53,  72],\n",
       "       [ 50, 102]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5145631067961165"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862068965517241"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_loop(predict_data, model_name):\n",
    "    scores = []\n",
    "    TPs = []\n",
    "    TNs = []\n",
    "    for randomize in range(1,20):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\",\"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=randomize)\n",
    "        if model_name == \"MLP\":\n",
    "            model = MLPClassifier(hidden_layer_sizes=(200,2000,200))\n",
    "        elif model_name == \"CAT\":\n",
    "            model = CatBoostClassifier(iterations=100,depth=12,verbose=False)\n",
    "        elif model_name == \"RF\":\n",
    "            model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "        model.fit(train_data, train_labels)\n",
    "        scores.append(model.score(test_data, test_labels))\n",
    "        conf = confusion_matrix(test_labels,model.predict(test_data))\n",
    "        TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "        TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "        TPs.append(TP)\n",
    "        TNs.append(TN)\n",
    "        print(\"Score : {} || TP : {} || TN : {}\".format(scores[-1],TP,TN))\n",
    "\n",
    "\n",
    "    return scores,TPs,TNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.5126353790613718 || TP : 0.5592105263157895 || TN : 0.456\n",
      "Score : 0.5090252707581228 || TP : 0.5337837837837838 || TN : 0.4806201550387597\n",
      "Score : 0.48014440433212996 || TP : 0.5272727272727272 || TN : 0.4107142857142857\n",
      "Score : 0.4981949458483754 || TP : 0.5277777777777778 || TN : 0.46616541353383456\n",
      "Score : 0.4693140794223827 || TP : 0.47282608695652173 || TN : 0.46236559139784944\n",
      "Score : 0.5487364620938628 || TP : 0.5806451612903226 || TN : 0.5081967213114754\n",
      "Score : 0.5415162454873647 || TP : 0.55 || TN : 0.5299145299145299\n",
      "Score : 0.49097472924187724 || TP : 0.5563380281690141 || TN : 0.4222222222222222\n",
      "Score : 0.4729241877256318 || TP : 0.5182926829268293 || TN : 0.40707964601769914\n",
      "Score : 0.4981949458483754 || TP : 0.5189873417721519 || TN : 0.47058823529411764\n",
      "Score : 0.5090252707581228 || TP : 0.5548387096774193 || TN : 0.45081967213114754\n",
      "Score : 0.5523465703971119 || TP : 0.5903614457831325 || TN : 0.4954954954954955\n",
      "Score : 0.48014440433212996 || TP : 0.5197368421052632 || TN : 0.432\n",
      "Score : 0.5126353790613718 || TP : 0.5584415584415584 || TN : 0.45528455284552843\n",
      "Score : 0.5054151624548736 || TP : 0.5031055900621118 || TN : 0.5086206896551724\n",
      "Score : 0.5090252707581228 || TP : 0.5317919075144508 || TN : 0.47115384615384615\n",
      "Score : 0.51985559566787 || TP : 0.5838926174496645 || TN : 0.4453125\n",
      "Score : 0.48375451263537905 || TP : 0.5283018867924528 || TN : 0.423728813559322\n",
      "Score : 0.5342960288808665 || TP : 0.5664739884393064 || TN : 0.4807692307692308\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"CAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen : 0.5067452023560707 || TP moyen : 0.5411620348700146 || TN moyen : 0.4619500842660272\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "print(\"CatBoost score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.49458483754512633 || TP : 0.5474452554744526 || TN : 0.44285714285714284\n",
      "Score : 0.48014440433212996 || TP : 0.506578947368421 || TN : 0.448\n",
      "Score : 0.5126353790613718 || TP : 0.5535714285714286 || TN : 0.44954128440366975\n",
      "Score : 0.51985559566787 || TP : 0.55 || TN : 0.48905109489051096\n",
      "Score : 0.4548736462093863 || TP : 0.45977011494252873 || TN : 0.44660194174757284\n",
      "Score : 0.48736462093862815 || TP : 0.5277777777777778 || TN : 0.44360902255639095\n",
      "Score : 0.516245487364621 || TP : 0.5272727272727272 || TN : 0.5\n",
      "Score : 0.516245487364621 || TP : 0.5827338129496403 || TN : 0.4492753623188406\n",
      "Score : 0.49097472924187724 || TP : 0.5329341317365269 || TN : 0.42727272727272725\n",
      "Score : 0.4548736462093863 || TP : 0.4797297297297297 || TN : 0.4263565891472868\n",
      "Score : 0.49097472924187724 || TP : 0.5379746835443038 || TN : 0.42857142857142855\n",
      "Score : 0.5631768953068592 || TP : 0.6 || TN : 0.5089285714285714\n",
      "Score : 0.4620938628158845 || TP : 0.5033557046979866 || TN : 0.4140625\n",
      "Score : 0.5090252707581228 || TP : 0.5534591194968553 || TN : 0.4491525423728814\n",
      "Score : 0.5126353790613718 || TP : 0.5089820359281437 || TN : 0.5181818181818182\n",
      "Score : 0.5415162454873647 || TP : 0.5625 || TN : 0.5128205128205128\n",
      "Score : 0.51985559566787 || TP : 0.5816993464052288 || TN : 0.4435483870967742\n",
      "Score : 0.5415162454873647 || TP : 0.5739644970414202 || TN : 0.49074074074074076\n",
      "Score : 0.5270758122743683 || TP : 0.5606936416184971 || TN : 0.47115384615384615\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen : 0.5050351510545317 || TP moyen : 0.539496997608193 || TN moyen : 0.4610381848716166\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.5451263537906137 || TP : 0.593103448275862 || TN : 0.49242424242424243\n",
      "Score : 0.48736462093862815 || TP : 0.5144927536231884 || TN : 0.460431654676259\n",
      "Score : 0.4981949458483754 || TP : 0.5522388059701493 || TN : 0.44755244755244755\n",
      "Score : 0.49458483754512633 || TP : 0.5228758169934641 || TN : 0.4596774193548387\n",
      "Score : 0.4981949458483754 || TP : 0.4935064935064935 || TN : 0.5040650406504065\n",
      "Score : 0.5487364620938628 || TP : 0.5850340136054422 || TN : 0.5076923076923077\n",
      "Score : 0.555956678700361 || TP : 0.5684931506849316 || TN : 0.5419847328244275\n",
      "Score : 0.5234657039711191 || TP : 0.5850340136054422 || TN : 0.45384615384615384\n",
      "Score : 0.5234657039711191 || TP : 0.5632911392405063 || TN : 0.47058823529411764\n",
      "Score : 0.516245487364621 || TP : 0.5379310344827586 || TN : 0.49242424242424243\n",
      "Score : 0.5415162454873647 || TP : 0.5833333333333334 || TN : 0.48760330578512395\n",
      "Score : 0.5523465703971119 || TP : 0.6013513513513513 || TN : 0.49612403100775193\n",
      "Score : 0.49458483754512633 || TP : 0.5347222222222222 || TN : 0.45112781954887216\n",
      "Score : 0.5595667870036101 || TP : 0.5987261146496815 || TN : 0.5083333333333333\n",
      "Score : 0.47653429602888087 || TP : 0.47586206896551725 || TN : 0.4772727272727273\n",
      "Score : 0.6064981949458483 || TP : 0.6461538461538462 || TN : 0.5714285714285714\n",
      "Score : 0.5667870036101083 || TP : 0.6376811594202898 || TN : 0.49640287769784175\n",
      "Score : 0.5234657039711191 || TP : 0.5625 || TN : 0.4700854700854701\n",
      "Score : 0.5306859205776173 || TP : 0.5670731707317073 || TN : 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP score moyen : 0.5285958578757363 || TP moyen : 0.5643896808850625 || TN moyen : 0.48773372205756976\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
