{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BTC-USD_SIGNALS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>Confirmation Time</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Miners Revenue</th>\n",
       "      <th>FnG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>10237.299805</td>\n",
       "      <td>10288.799805</td>\n",
       "      <td>8812.280273</td>\n",
       "      <td>9170.540039</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-2.712213</td>\n",
       "      <td>-1.043523</td>\n",
       "      <td>-1.108359</td>\n",
       "      <td>-0.475907</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.583209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>9142.280273</td>\n",
       "      <td>9142.280273</td>\n",
       "      <td>7796.490234</td>\n",
       "      <td>8830.750000</td>\n",
       "      <td>-0.152676</td>\n",
       "      <td>-1.011481</td>\n",
       "      <td>-1.204172</td>\n",
       "      <td>-1.202571</td>\n",
       "      <td>-0.654534</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-1.244407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>8852.120117</td>\n",
       "      <td>9430.750000</td>\n",
       "      <td>8251.629883</td>\n",
       "      <td>9174.910156</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>9175.700195</td>\n",
       "      <td>9334.870117</td>\n",
       "      <td>8031.220215</td>\n",
       "      <td>8277.009766</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>8270.540039</td>\n",
       "      <td>8364.839844</td>\n",
       "      <td>6756.680176</td>\n",
       "      <td>6955.270020</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>19832.470703</td>\n",
       "      <td>19999.689453</td>\n",
       "      <td>19636.816406</td>\n",
       "      <td>19986.712891</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>-1.113287</td>\n",
       "      <td>-0.844382</td>\n",
       "      <td>-0.254845</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-1.024008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>19988.789063</td>\n",
       "      <td>20031.160156</td>\n",
       "      <td>19673.046875</td>\n",
       "      <td>19812.371094</td>\n",
       "      <td>0.658018</td>\n",
       "      <td>-0.278482</td>\n",
       "      <td>-1.133325</td>\n",
       "      <td>-0.831832</td>\n",
       "      <td>-0.166540</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.891768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>19817.724609</td>\n",
       "      <td>20155.269531</td>\n",
       "      <td>18800.171875</td>\n",
       "      <td>18837.667969</td>\n",
       "      <td>1.393318</td>\n",
       "      <td>-1.325705</td>\n",
       "      <td>-1.548973</td>\n",
       "      <td>-0.892284</td>\n",
       "      <td>-0.308652</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-0.935848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>18837.683594</td>\n",
       "      <td>19427.171875</td>\n",
       "      <td>18644.466797</td>\n",
       "      <td>19290.324219</td>\n",
       "      <td>0.981876</td>\n",
       "      <td>0.568952</td>\n",
       "      <td>-1.180050</td>\n",
       "      <td>-0.893278</td>\n",
       "      <td>-0.249058</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-0.847688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>19289.941406</td>\n",
       "      <td>19417.351563</td>\n",
       "      <td>19076.714844</td>\n",
       "      <td>19329.833984</td>\n",
       "      <td>0.828407</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-1.279608</td>\n",
       "      <td>-0.881242</td>\n",
       "      <td>-0.163410</td>\n",
       "      <td>-0.653287</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-1.024008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open  ...  Miners Revenue       FnG\n",
       "0     2018-02-01  10237.299805  ...       -0.186892 -0.583209\n",
       "1     2018-02-02   9142.280273  ...       -0.186892 -1.244407\n",
       "2     2018-02-03   8852.120117  ...       -0.186892 -0.142410\n",
       "3     2018-02-04   9175.700195  ...       -0.264496 -0.847688\n",
       "4     2018-02-05   8270.540039  ...       -0.264496 -1.420727\n",
       "...          ...           ...  ...             ...       ...\n",
       "1679  2022-09-04  19832.470703  ...       -0.307825 -1.024008\n",
       "1680  2022-09-05  19988.789063  ...       -0.307825 -0.891768\n",
       "1681  2022-09-06  19817.724609  ...       -0.359746 -0.935848\n",
       "1682  2022-09-07  18837.683594  ...       -0.359746 -0.847688\n",
       "1683  2022-09-08  19289.941406  ...       -0.359746 -1.024008\n",
       "\n",
       "[1684 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = data.copy().drop([\"Open\",\"Close\",\"High\",\"Low\"],axis=1)\n",
    "max_days = 5\n",
    "target_range = 2\n",
    "for i in range(1,max_days):#2jours\n",
    "    predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\"]].shift(i)\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\"]].shift(i)\n",
    "#predict_data[\"Target\"] = (data[\"Variation\"].shift(-1) >= 0)\n",
    "predict_data[\"Target\"] = (data[\"Close\"].shift(-target_range) - data[\"Close\"] >= 0)\n",
    "predict_data[\"Target\"] = np.where(predict_data[\"Target\"] == True, 1, 0)\n",
    "predict_data.dropna(inplace=True)\n",
    "predict_data.reset_index(inplace=True,drop=True)\n",
    "predict_data = predict_data[0:len(predict_data)-target_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = predict_data[[i % int(max_days / 3) == 0 for i in range(len(predict_data))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>Confirmation Time</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Miners Revenue</th>\n",
       "      <th>FnG</th>\n",
       "      <th>Variation-1</th>\n",
       "      <th>Vol-1</th>\n",
       "      <th>RSI-1</th>\n",
       "      <th>MACD-1</th>\n",
       "      <th>MACD_H-1</th>\n",
       "      <th>CONF-1</th>\n",
       "      <th>TRANS-1</th>\n",
       "      <th>REV-1</th>\n",
       "      <th>FnG-1</th>\n",
       "      <th>Variation-2</th>\n",
       "      <th>Vol-2</th>\n",
       "      <th>RSI-2</th>\n",
       "      <th>MACD-2</th>\n",
       "      <th>MACD_H-2</th>\n",
       "      <th>CONF-2</th>\n",
       "      <th>TRANS-2</th>\n",
       "      <th>REV-2</th>\n",
       "      <th>FnG-2</th>\n",
       "      <th>Variation-3</th>\n",
       "      <th>Vol-3</th>\n",
       "      <th>RSI-3</th>\n",
       "      <th>MACD-3</th>\n",
       "      <th>MACD_H-3</th>\n",
       "      <th>CONF-3</th>\n",
       "      <th>TRANS-3</th>\n",
       "      <th>REV-3</th>\n",
       "      <th>FnG-3</th>\n",
       "      <th>Variation-4</th>\n",
       "      <th>Vol-4</th>\n",
       "      <th>RSI-4</th>\n",
       "      <th>MACD-4</th>\n",
       "      <th>MACD_H-4</th>\n",
       "      <th>CONF-4</th>\n",
       "      <th>TRANS-4</th>\n",
       "      <th>REV-4</th>\n",
       "      <th>FnG-4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "      <td>-1.011481</td>\n",
       "      <td>-0.152676</td>\n",
       "      <td>-1.204172</td>\n",
       "      <td>-1.202571</td>\n",
       "      <td>-0.654534</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-1.244407</td>\n",
       "      <td>-2.712213</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-1.043523</td>\n",
       "      <td>-1.108359</td>\n",
       "      <td>-0.475907</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.583209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>-0.088527</td>\n",
       "      <td>2.918547</td>\n",
       "      <td>-1.212491</td>\n",
       "      <td>-1.523793</td>\n",
       "      <td>-0.973190</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.552966</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "      <td>-1.011481</td>\n",
       "      <td>-0.152676</td>\n",
       "      <td>-1.204172</td>\n",
       "      <td>-1.202571</td>\n",
       "      <td>-0.654534</td>\n",
       "      <td>1.144750</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-1.244407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>-0.495589</td>\n",
       "      <td>-1.457407</td>\n",
       "      <td>-1.552132</td>\n",
       "      <td>-0.860381</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.318730</td>\n",
       "      <td>2.918547</td>\n",
       "      <td>-0.088527</td>\n",
       "      <td>-1.212491</td>\n",
       "      <td>-1.523793</td>\n",
       "      <td>-0.973190</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.552966</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>-1.632900</td>\n",
       "      <td>-1.235294</td>\n",
       "      <td>-0.618233</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-0.774692</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>-0.142410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>-0.323021</td>\n",
       "      <td>2.134561</td>\n",
       "      <td>-1.063630</td>\n",
       "      <td>-1.504877</td>\n",
       "      <td>-0.549827</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.583209</td>\n",
       "      <td>-0.495589</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>-1.457407</td>\n",
       "      <td>-1.552132</td>\n",
       "      <td>-0.860381</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.318730</td>\n",
       "      <td>2.918547</td>\n",
       "      <td>-0.088527</td>\n",
       "      <td>-1.212491</td>\n",
       "      <td>-1.523793</td>\n",
       "      <td>-0.973190</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.552966</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>-2.584947</td>\n",
       "      <td>-0.437581</td>\n",
       "      <td>-1.626830</td>\n",
       "      <td>-1.320379</td>\n",
       "      <td>-0.741794</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.847688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>-0.452131</td>\n",
       "      <td>1.422827</td>\n",
       "      <td>-0.830140</td>\n",
       "      <td>-1.412981</td>\n",
       "      <td>-0.171285</td>\n",
       "      <td>0.207605</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>2.134561</td>\n",
       "      <td>-0.323021</td>\n",
       "      <td>-1.063630</td>\n",
       "      <td>-1.504877</td>\n",
       "      <td>-0.549827</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.583209</td>\n",
       "      <td>-0.495589</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>-1.457407</td>\n",
       "      <td>-1.552132</td>\n",
       "      <td>-0.860381</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.959889</td>\n",
       "      <td>-0.596734</td>\n",
       "      <td>-0.318730</td>\n",
       "      <td>2.918547</td>\n",
       "      <td>-0.088527</td>\n",
       "      <td>-1.212491</td>\n",
       "      <td>-1.523793</td>\n",
       "      <td>-0.973190</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.552966</td>\n",
       "      <td>-4.184569</td>\n",
       "      <td>-0.326118</td>\n",
       "      <td>-1.814295</td>\n",
       "      <td>-1.479953</td>\n",
       "      <td>-1.057732</td>\n",
       "      <td>1.114249</td>\n",
       "      <td>-1.144752</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-1.420727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>0.673668</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>-0.707947</td>\n",
       "      <td>-0.867803</td>\n",
       "      <td>-0.506193</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>0.277823</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>-1.406081</td>\n",
       "      <td>-0.880154</td>\n",
       "      <td>-0.841249</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>-0.691652</td>\n",
       "      <td>0.943757</td>\n",
       "      <td>-1.653641</td>\n",
       "      <td>-0.871357</td>\n",
       "      <td>-1.020465</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.715449</td>\n",
       "      <td>0.845674</td>\n",
       "      <td>0.850751</td>\n",
       "      <td>-1.597787</td>\n",
       "      <td>-0.821959</td>\n",
       "      <td>-1.096574</td>\n",
       "      <td>-1.263537</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.847688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>0.395940</td>\n",
       "      <td>-0.231177</td>\n",
       "      <td>-0.964656</td>\n",
       "      <td>-0.866931</td>\n",
       "      <td>-0.401653</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.979928</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>0.673668</td>\n",
       "      <td>-0.707947</td>\n",
       "      <td>-0.867803</td>\n",
       "      <td>-0.506193</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>0.277823</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>-1.406081</td>\n",
       "      <td>-0.880154</td>\n",
       "      <td>-0.841249</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>-0.691652</td>\n",
       "      <td>0.943757</td>\n",
       "      <td>-1.653641</td>\n",
       "      <td>-0.871357</td>\n",
       "      <td>-1.020465</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-1.414496</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>-0.715449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>-1.113287</td>\n",
       "      <td>-0.844382</td>\n",
       "      <td>-0.254845</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>-0.231177</td>\n",
       "      <td>0.395940</td>\n",
       "      <td>-0.964656</td>\n",
       "      <td>-0.866931</td>\n",
       "      <td>-0.401653</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.979928</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>0.673668</td>\n",
       "      <td>-0.707947</td>\n",
       "      <td>-0.867803</td>\n",
       "      <td>-0.506193</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>0.277823</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>-1.406081</td>\n",
       "      <td>-0.880154</td>\n",
       "      <td>-0.841249</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>0.658018</td>\n",
       "      <td>-0.278482</td>\n",
       "      <td>-1.133325</td>\n",
       "      <td>-0.831832</td>\n",
       "      <td>-0.166540</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>-1.113287</td>\n",
       "      <td>-0.844382</td>\n",
       "      <td>-0.254845</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>-0.231177</td>\n",
       "      <td>0.395940</td>\n",
       "      <td>-0.964656</td>\n",
       "      <td>-0.866931</td>\n",
       "      <td>-0.401653</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.979928</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>0.673668</td>\n",
       "      <td>-0.707947</td>\n",
       "      <td>-0.867803</td>\n",
       "      <td>-0.506193</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.726988</td>\n",
       "      <td>-1.336325</td>\n",
       "      <td>-0.871305</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-1.313931</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>1.393318</td>\n",
       "      <td>-1.325705</td>\n",
       "      <td>-1.548973</td>\n",
       "      <td>-0.892284</td>\n",
       "      <td>-0.308652</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-0.359746</td>\n",
       "      <td>-0.935848</td>\n",
       "      <td>-0.278482</td>\n",
       "      <td>0.658018</td>\n",
       "      <td>-1.133325</td>\n",
       "      <td>-0.831832</td>\n",
       "      <td>-0.166540</td>\n",
       "      <td>-0.742360</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.891768</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>-1.113287</td>\n",
       "      <td>-0.844382</td>\n",
       "      <td>-0.254845</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-1.024008</td>\n",
       "      <td>-0.231177</td>\n",
       "      <td>0.395940</td>\n",
       "      <td>-0.964656</td>\n",
       "      <td>-0.866931</td>\n",
       "      <td>-0.401653</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.648298</td>\n",
       "      <td>-0.307825</td>\n",
       "      <td>-0.979928</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>0.673668</td>\n",
       "      <td>-0.707947</td>\n",
       "      <td>-0.867803</td>\n",
       "      <td>-0.506193</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-0.310919</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1678 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Volume  Variation  ...     REV-4     FnG-4  Target\n",
       "0     2018-02-05 -0.326118  -4.184569  ... -0.186892 -0.583209       1\n",
       "1     2018-02-06 -0.088527   2.918547  ... -0.186892 -1.244407       1\n",
       "2     2018-02-07 -0.331965  -0.495589  ... -0.186892 -0.142410       1\n",
       "3     2018-02-08 -0.323021   2.134561  ... -0.264496 -0.847688       1\n",
       "4     2018-02-09 -0.452131   1.422827  ... -0.264496 -1.420727       0\n",
       "...          ...       ...        ...  ...       ...       ...     ...\n",
       "1673  2022-09-02  0.673668  -0.255088  ... -0.174982 -0.847688       1\n",
       "1674  2022-09-03  0.395940  -0.231177  ... -0.174982 -0.715449       0\n",
       "1675  2022-09-04  0.478227   0.148948  ... -0.277036 -0.891768       0\n",
       "1676  2022-09-05  0.658018  -0.278482  ... -0.277036 -1.024008       0\n",
       "1677  2022-09-06  1.393318  -1.325705  ... -0.277036 -0.803608       1\n",
       "\n",
       "[1678 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = predict_data.corr(\"pearson\")\n",
    "#corr[[\"Target\"]].to_clipboard()\n",
    "#corr[[\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mode = \"RAND\"\n",
    "\n",
    "if split_mode == \"RAND\":\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\",\"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=100)\n",
    "elif split_mode == \"STATIC\":\n",
    "    train_data = predict_data[0:int(0.66*len(predict_data))].drop([\"Date\",\"Target\"],axis=1)\n",
    "    train_labels = predict_data[0:int(0.66*len(predict_data))][\"Target\"]\n",
    "    test_data = predict_data[int(0.66*len(predict_data)):len(predict_data)].drop([\"Date\",\"Target\"],axis=1)\n",
    "    test_labels = predict_data[int(0.66*len(predict_data)):len(predict_data)][\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.74636336\n",
      "Iteration 2, loss = 0.69649579\n",
      "Iteration 3, loss = 0.67046350\n",
      "Iteration 4, loss = 0.66180363\n",
      "Iteration 5, loss = 0.65379488\n",
      "Iteration 6, loss = 0.63297506\n",
      "Iteration 7, loss = 0.61386179\n",
      "Iteration 8, loss = 0.58982201\n",
      "Iteration 9, loss = 0.56679113\n",
      "Iteration 10, loss = 0.53945868\n",
      "Iteration 11, loss = 0.51540729\n",
      "Iteration 12, loss = 0.50061452\n",
      "Iteration 13, loss = 0.46480858\n",
      "Iteration 14, loss = 0.43590603\n",
      "Iteration 15, loss = 0.39575270\n",
      "Iteration 16, loss = 0.37467826\n",
      "Iteration 17, loss = 0.33360911\n",
      "Iteration 18, loss = 0.30891724\n",
      "Iteration 19, loss = 0.28295675\n",
      "Iteration 20, loss = 0.24615849\n",
      "Iteration 21, loss = 0.22562006\n",
      "Iteration 22, loss = 0.21413693\n",
      "Iteration 23, loss = 0.18695444\n",
      "Iteration 24, loss = 0.18091632\n",
      "Iteration 25, loss = 0.15884428\n",
      "Iteration 26, loss = 0.14444562\n",
      "Iteration 27, loss = 0.11347248\n",
      "Iteration 28, loss = 0.09183450\n",
      "Iteration 29, loss = 0.06705855\n",
      "Iteration 30, loss = 0.05440977\n",
      "Iteration 31, loss = 0.04569979\n",
      "Iteration 32, loss = 0.03384509\n",
      "Iteration 33, loss = 0.03048132\n",
      "Iteration 34, loss = 0.02905880\n",
      "Iteration 35, loss = 0.03563323\n",
      "Iteration 36, loss = 0.03116591\n",
      "Iteration 37, loss = 0.03136551\n",
      "Iteration 38, loss = 0.05886289\n",
      "Iteration 39, loss = 0.08319388\n",
      "Iteration 40, loss = 0.10055669\n",
      "Iteration 41, loss = 0.11934963\n",
      "Iteration 42, loss = 0.08290255\n",
      "Iteration 43, loss = 0.06270636\n",
      "Iteration 44, loss = 0.04897072\n",
      "Iteration 45, loss = 0.03724355\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(200, 2000, 200), verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = \"MLP\"\n",
    "\n",
    "if algo == \"MLP\":\n",
    "    model = MLPClassifier(hidden_layer_sizes=(200,2000,200),verbose=True)\n",
    "elif algo == \"RF\":\n",
    "    model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "elif algo == \"CAT\":\n",
    "    model = CatBoostClassifier(iterations=100,depth=12)\n",
    "elif algo == \"TREE\":\n",
    "    model = DecisionTreeClassifier(splitter=\"random\")\n",
    "model.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046931407942239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973309608540926"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 116],\n",
       "       [103, 190]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5846774193548387"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6209150326797386"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_loop(predict_data):\n",
    "    scores = []\n",
    "    TPs = []\n",
    "    TNs = []\n",
    "    for randomize in range(1,20):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\",\"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=randomize)\n",
    "        model = MLPClassifier(hidden_layer_sizes=(200,2000,200))\n",
    "        model.fit(train_data, train_labels)\n",
    "        scores.append(model.score(test_data, test_labels))\n",
    "        conf = confusion_matrix(test_labels,model.predict(test_data))\n",
    "        TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "        TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "        TPs.append(TP)\n",
    "        TNs.append(TN)\n",
    "        print(\"Score : {} || TP : {} || TN : {}\".format(scores[-1],TP,TN))\n",
    "\n",
    "\n",
    "    return scores,TPs,TNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.5848375451263538 || TP : 0.6115107913669064 || TN : 0.5579710144927537\n",
      "Score : 0.5649819494584838 || TP : 0.5966666666666667 || TN : 0.5275590551181102\n",
      "Score : 0.5794223826714802 || TP : 0.5935483870967742 || TN : 0.5614754098360656\n",
      "Score : 0.5848375451263538 || TP : 0.6140350877192983 || TN : 0.5539033457249071\n",
      "Score : 0.5794223826714802 || TP : 0.603125 || TN : 0.5470085470085471\n",
      "Score : 0.592057761732852 || TP : 0.6084142394822006 || TN : 0.5714285714285714\n",
      "Score : 0.5866425992779783 || TP : 0.6142857142857143 || TN : 0.5583941605839416\n",
      "Score : 0.6101083032490975 || TP : 0.6466666666666666 || TN : 0.5669291338582677\n",
      "Score : 0.572202166064982 || TP : 0.6214285714285714 || TN : 0.5218978102189781\n",
      "Score : 0.6101083032490975 || TP : 0.5973597359735974 || TN : 0.6254980079681275\n",
      "Score : 0.6101083032490975 || TP : 0.6351791530944625 || TN : 0.5789473684210527\n",
      "Score : 0.555956678700361 || TP : 0.5471014492753623 || TN : 0.564748201438849\n",
      "Score : 0.5902527075812274 || TP : 0.5882352941176471 || TN : 0.592741935483871\n",
      "Score : 0.575812274368231 || TP : 0.592948717948718 || TN : 0.5537190082644629\n",
      "Score : 0.5866425992779783 || TP : 0.6161971830985915 || TN : 0.5555555555555556\n",
      "Score : 0.5613718411552346 || TP : 0.6013986013986014 || TN : 0.5186567164179104\n",
      "Score : 0.572202166064982 || TP : 0.6 || TN : 0.5416666666666666\n",
      "Score : 0.575812274368231 || TP : 0.6028880866425993 || TN : 0.5487364620938628\n",
      "Score : 0.6083032490974729 || TP : 0.6343042071197411 || TN : 0.5755102040816327\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen : 0.5842675280258408 || TP moyen : 0.6065943975464273 || TN moyen : 0.559070903929586\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "print(\"score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d62b7309829161c9ff8c8cb2799597e552c804f98ee796508f623761c3c8a87d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
