{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datahandler import *\n",
    "from playground import *\n",
    "from gui import *\n",
    "from torchutils import *\n",
    "from models import *\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 15\n",
    "agent_horizon = 10\n",
    "crossover_horizon = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not add indicator OBV\n",
      "Error message 'Volume'\n",
      "Ignoring indicator OBV. Reason: Not found in the list of indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data['Target'] = handler.data['Label']\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[f'MA{ma1} Var'], predict_data[f'MA{ma2} Var'] = handler.data[f'MA{ma1} Var'], handler.data[f'MA{ma2} Var']\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[f'MA{ma1} Var'], predict_data[f'MA{ma2} Var'] = handler.data[f'MA{ma1} Var'], handler.data[f'MA{ma2} Var']\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[dummies.columns] = handler.data[dummies.columns]\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[dummies.columns] = handler.data[dummies.columns]\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[dummies.columns] = handler.data[dummies.columns]\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data['Crossover'] = handler.data['Crossover']\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[f'MA{ma1} UP'], predict_data[f'MA{ma2} UP'] = (\n",
      "C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_15284\\2085278819.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predict_data[f'MA{ma1} UP'], predict_data[f'MA{ma2} UP'] = (\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "if not os.path.exists('./BTCUSDT_DB.csv'):\n",
    "    data = pd.read_csv(\"BTCUSDT_1m.csv\")\n",
    "    data = get_dollar_bars(data)\n",
    "    data.to_csv('./BTCUSDT_DB.csv', sep=',')\n",
    "else:\n",
    "    data = pd.read_csv('./BTCUSDT_DB.csv', sep=',')\n",
    "\n",
    "handler = NewDataHandler(dataset=data)\n",
    "\n",
    "ma1, ma2 = 5, 10\n",
    "handler.data = ma_crossover_labelling(\n",
    "    handler.data, ma1, ma2, crossover_horizon)\n",
    "handler.data.rename({'Label': 'Crossover'}, axis=1, inplace=True)\n",
    "dummies = pd.get_dummies(handler.data['Crossover'], prefix='Crossover') * 1\n",
    "# handler.data.drop('Crossover', axis=1, inplace=True)\n",
    "handler.data = pd.concat([handler.data, dummies], axis=1)\n",
    "handler.data = triple_barrier_labelling(handler.data, time_limit=agent_horizon)\n",
    "\n",
    "handler.add_indicators([Indicators.RSI, Indicators.MACD,\n",
    "                       Indicators.ADX, Indicators.OBV, Indicators.TICK_DENSITY])\n",
    "\n",
    "handler.create_var_indicator([Indicators.RSI, Indicators.MACD, Indicators.ADX, Indicators.OBV, Indicators.PERC_RET,\n",
    "                              Indicators.TICK_DENSITY])\n",
    "\n",
    "# display(handler.data[handler.data.isnull().any(axis=1)]) # Displaying all the rows that contain missing values to see if they are spread across the dataframe\n",
    "\n",
    "handler.data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# handler.standardize_data()\n",
    "\n",
    "handler.data.dropna(axis=0, inplace=True)\n",
    "\n",
    "handler.create_predict_data()\n",
    "\n",
    "predict_data = handler.predict_data\n",
    "predict_data['Target'] = handler.data['Label']\n",
    "predict_data[f'MA{ma1} Var'], predict_data[f'MA{ma2} Var'] = handler.data[f'MA{ma1} Var'], handler.data[f'MA{ma2} Var']\n",
    "predict_data[dummies.columns] = handler.data[dummies.columns]\n",
    "predict_data['Crossover'] = handler.data['Crossover']\n",
    "predict_data[f'MA{ma1} UP'], predict_data[f'MA{ma2} UP'] = (\n",
    "    handler.data[f'MA{ma1}'] > handler.data[f'MA{ma2}']) * 1, (handler.data[f'MA{ma1}'] < handler.data[f'MA{ma2}']) * 1\n",
    "predict_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossover_lstm_model = torch.load(\n",
    "    f'./models/crossover_{seq_length}_to_{crossover_horizon}.pt')\n",
    "lstm_model = torch.load(f'./models/agent_{seq_length}_to_{agent_horizon}.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Creating Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_columns = predict_data.drop(['Crossover'], axis=1).columns\n",
    "crossover_columns = predict_data.drop(dummies.columns, axis=1).columns\n",
    "ma_dataset = TSDataset(\n",
    "    predict_data[crossover_columns], seq_length, 'Crossover')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing real crossover predictions by infered crossover predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5937994573818675 || Loss : 0.9271247982978821\n",
      "Confusion matrix : \n",
      "[[7.231e+03 5.180e+02 1.000e+00]\n",
      " [7.375e+03 7.080e+03 5.425e+03]\n",
      " [1.500e+01 1.039e+03 6.700e+03]]\n"
     ]
    }
   ],
   "source": [
    "predicted_crossover_outputs, predicted_crossover_targets = eval_lstm(crossover_lstm_model, ma_dataset, len(\n",
    "    ma_dataset), crossover_lstm_model.num_layers, crossover_lstm_model.hidden_size, device)\n",
    "\n",
    "predicted_crossover_outputs = pd.Series(\n",
    "    (torch.argmax(predicted_crossover_outputs, axis=-1) - 1).cpu()).shift(seq_length)\n",
    "\n",
    "crossover_prediction_dummies = pd.get_dummies(\n",
    "    predicted_crossover_outputs, prefix='Crossover') * 1\n",
    "\n",
    "transition_predict_data = predict_data.copy()\n",
    "transition_predict_data[dummies.columns] = crossover_prediction_dummies\n",
    "transition_predict_data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSDataset(transition_predict_data[trade_columns], seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>RSI Var</th>\n",
       "      <th>MACD Var</th>\n",
       "      <th>MACD_H Var</th>\n",
       "      <th>ADX14 Var</th>\n",
       "      <th>-DM Var</th>\n",
       "      <th>+DM Var</th>\n",
       "      <th>TICK_DENSITY Var</th>\n",
       "      <th>PERC_RET</th>\n",
       "      <th>Target</th>\n",
       "      <th>MA5 Var</th>\n",
       "      <th>MA10 Var</th>\n",
       "      <th>Crossover_-1</th>\n",
       "      <th>Crossover_0</th>\n",
       "      <th>Crossover_1</th>\n",
       "      <th>Crossover</th>\n",
       "      <th>MA5 UP</th>\n",
       "      <th>MA10 UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1513428720000</td>\n",
       "      <td>0.048401</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>-0.405401</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>-0.081688</td>\n",
       "      <td>0.192699</td>\n",
       "      <td>0.140838</td>\n",
       "      <td>0.080168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1513501980000</td>\n",
       "      <td>-0.020026</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.265815</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>-0.024363</td>\n",
       "      <td>0.123226</td>\n",
       "      <td>-0.008869</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.035187</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1513550040000</td>\n",
       "      <td>-0.033514</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>0.064192</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>-0.112892</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1513582380000</td>\n",
       "      <td>-0.034835</td>\n",
       "      <td>-0.032725</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>-0.028909</td>\n",
       "      <td>-0.060343</td>\n",
       "      <td>-0.060343</td>\n",
       "      <td>-0.059421</td>\n",
       "      <td>-0.014598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1513633980000</td>\n",
       "      <td>-0.159429</td>\n",
       "      <td>-0.083628</td>\n",
       "      <td>0.757608</td>\n",
       "      <td>-0.067444</td>\n",
       "      <td>0.359299</td>\n",
       "      <td>-0.112219</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007263</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35394</th>\n",
       "      <td>1685407200000</td>\n",
       "      <td>0.086249</td>\n",
       "      <td>-0.060071</td>\n",
       "      <td>-0.103070</td>\n",
       "      <td>-0.014485</td>\n",
       "      <td>-0.098990</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>0.083067</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35395</th>\n",
       "      <td>1685420640000</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>-0.052760</td>\n",
       "      <td>-0.110785</td>\n",
       "      <td>-0.013648</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>0.150442</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35396</th>\n",
       "      <td>1685435400000</td>\n",
       "      <td>0.094888</td>\n",
       "      <td>0.042184</td>\n",
       "      <td>-0.275985</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>-0.086009</td>\n",
       "      <td>0.155933</td>\n",
       "      <td>0.251282</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35397</th>\n",
       "      <td>1685443800000</td>\n",
       "      <td>-0.057433</td>\n",
       "      <td>-0.019390</td>\n",
       "      <td>-0.149725</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>-0.059869</td>\n",
       "      <td>-0.058333</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35398</th>\n",
       "      <td>1685494260000</td>\n",
       "      <td>-0.042508</td>\n",
       "      <td>-0.166193</td>\n",
       "      <td>0.030259</td>\n",
       "      <td>-0.050863</td>\n",
       "      <td>0.071720</td>\n",
       "      <td>-0.086337</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35399 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unix   RSI Var  MACD Var  MACD_H Var  ADX14 Var   -DM Var   \n",
       "0      1513428720000  0.048401  0.029123   -0.405401   0.015614 -0.081688  \\\n",
       "1      1513501980000 -0.020026  0.005391   -0.265815   0.016594 -0.062304   \n",
       "2      1513550040000 -0.033514 -0.015804    0.064192  -0.031174  0.580984   \n",
       "3      1513582380000 -0.034835 -0.032725    0.305927  -0.028909 -0.060343   \n",
       "4      1513633980000 -0.159429 -0.083628    0.757608  -0.067444  0.359299   \n",
       "...              ...       ...       ...         ...        ...       ...   \n",
       "35394  1685407200000  0.086249 -0.060071   -0.103070  -0.014485 -0.098990   \n",
       "35395  1685420640000  0.009836 -0.052760   -0.110785  -0.013648 -0.057964   \n",
       "35396  1685435400000  0.094888  0.042184   -0.275985   0.009149 -0.086009   \n",
       "35397  1685443800000 -0.057433 -0.019390   -0.149725   0.008564 -0.059869   \n",
       "35398  1685494260000 -0.042508 -0.166193    0.030259  -0.050863  0.071720   \n",
       "\n",
       "        +DM Var  TICK_DENSITY Var  PERC_RET  Target   MA5 Var  MA10 Var   \n",
       "0      0.192699          0.140838  0.080168     0.0  0.039638  0.017862  \\\n",
       "1     -0.024363          0.123226 -0.008869    -1.0  0.035187  0.017930   \n",
       "2     -0.112892          0.026073 -0.014388     0.0  0.028830  0.014729   \n",
       "3     -0.060343         -0.059421 -0.014598     0.0  0.007641  0.011799   \n",
       "4     -0.112219          0.010391 -0.074901     0.0 -0.007263  0.008164   \n",
       "...         ...               ...       ...     ...       ...       ...   \n",
       "35394  0.057578          0.083067  0.004759    -1.0  0.000256 -0.001026   \n",
       "35395 -0.057964          0.150442  0.000612    -1.0  0.000918 -0.000541   \n",
       "35396  0.155933          0.251282  0.006472    -1.0  0.002406  0.000461   \n",
       "35397 -0.058333          0.066598 -0.002737    -1.0  0.001621 -0.000033   \n",
       "35398 -0.086337          0.308642 -0.001955    -1.0 -0.000941  0.000077   \n",
       "\n",
       "       Crossover_-1  Crossover_0  Crossover_1  Crossover  MA5 UP  MA10 UP  \n",
       "0                 0            1            0          0       1        0  \n",
       "1                 1            0            0         -1       1        0  \n",
       "2                 1            0            0         -1       1        0  \n",
       "3                 1            0            0         -1       1        0  \n",
       "4                 1            0            0         -1       1        0  \n",
       "...             ...          ...          ...        ...     ...      ...  \n",
       "35394             0            0            1          1       0        1  \n",
       "35395             0            0            1          1       0        1  \n",
       "35396             0            1            0          0       0        1  \n",
       "35397             1            0            0         -1       1        0  \n",
       "35398             0            0            1          1       0        1  \n",
       "\n",
       "[35399 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>RSI Var</th>\n",
       "      <th>MACD Var</th>\n",
       "      <th>MACD_H Var</th>\n",
       "      <th>ADX14 Var</th>\n",
       "      <th>-DM Var</th>\n",
       "      <th>+DM Var</th>\n",
       "      <th>TICK_DENSITY Var</th>\n",
       "      <th>PERC_RET</th>\n",
       "      <th>Target</th>\n",
       "      <th>MA5 Var</th>\n",
       "      <th>MA10 Var</th>\n",
       "      <th>Crossover_-1</th>\n",
       "      <th>Crossover_0</th>\n",
       "      <th>Crossover_1</th>\n",
       "      <th>Crossover</th>\n",
       "      <th>MA5 UP</th>\n",
       "      <th>MA10 UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1513428720000</td>\n",
       "      <td>0.048401</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>-0.405401</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>-0.081688</td>\n",
       "      <td>0.192699</td>\n",
       "      <td>0.140838</td>\n",
       "      <td>0.080168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1513501980000</td>\n",
       "      <td>-0.020026</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.265815</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>-0.024363</td>\n",
       "      <td>0.123226</td>\n",
       "      <td>-0.008869</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.035187</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1513550040000</td>\n",
       "      <td>-0.033514</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>0.064192</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>-0.112892</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1513582380000</td>\n",
       "      <td>-0.034835</td>\n",
       "      <td>-0.032725</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>-0.028909</td>\n",
       "      <td>-0.060343</td>\n",
       "      <td>-0.060343</td>\n",
       "      <td>-0.059421</td>\n",
       "      <td>-0.014598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1513633980000</td>\n",
       "      <td>-0.159429</td>\n",
       "      <td>-0.083628</td>\n",
       "      <td>0.757608</td>\n",
       "      <td>-0.067444</td>\n",
       "      <td>0.359299</td>\n",
       "      <td>-0.112219</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007263</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35379</th>\n",
       "      <td>1685309400000</td>\n",
       "      <td>0.085803</td>\n",
       "      <td>0.182759</td>\n",
       "      <td>0.281196</td>\n",
       "      <td>0.080652</td>\n",
       "      <td>-0.167365</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35380</th>\n",
       "      <td>1685311380000</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.115898</td>\n",
       "      <td>0.081708</td>\n",
       "      <td>0.069302</td>\n",
       "      <td>-0.034564</td>\n",
       "      <td>-0.034564</td>\n",
       "      <td>-0.233618</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35381</th>\n",
       "      <td>1685314680000</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.074445</td>\n",
       "      <td>-0.013330</td>\n",
       "      <td>0.065175</td>\n",
       "      <td>-0.064475</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>-0.260223</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35382</th>\n",
       "      <td>1685318520000</td>\n",
       "      <td>0.029080</td>\n",
       "      <td>0.087796</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>0.063541</td>\n",
       "      <td>-0.099579</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>-0.148241</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35383</th>\n",
       "      <td>1685320260000</td>\n",
       "      <td>-0.100542</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>-0.153452</td>\n",
       "      <td>0.055477</td>\n",
       "      <td>-0.070788</td>\n",
       "      <td>-0.070788</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>-0.006221</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35384 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unix   RSI Var  MACD Var  MACD_H Var  ADX14 Var   -DM Var   \n",
       "0      1513428720000  0.048401  0.029123   -0.405401   0.015614 -0.081688  \\\n",
       "1      1513501980000 -0.020026  0.005391   -0.265815   0.016594 -0.062304   \n",
       "2      1513550040000 -0.033514 -0.015804    0.064192  -0.031174  0.580984   \n",
       "3      1513582380000 -0.034835 -0.032725    0.305927  -0.028909 -0.060343   \n",
       "4      1513633980000 -0.159429 -0.083628    0.757608  -0.067444  0.359299   \n",
       "...              ...       ...       ...         ...        ...       ...   \n",
       "35379  1685309400000  0.085803  0.182759    0.281196   0.080652 -0.167365   \n",
       "35380  1685311380000  0.003448  0.115898    0.081708   0.069302 -0.034564   \n",
       "35381  1685314680000  0.002886  0.074445   -0.013330   0.065175 -0.064475   \n",
       "35382  1685318520000  0.029080  0.087796    0.039732   0.063541 -0.099579   \n",
       "35383  1685320260000 -0.100542  0.016294   -0.153452   0.055477 -0.070788   \n",
       "\n",
       "        +DM Var  TICK_DENSITY Var  PERC_RET  Target   MA5 Var  MA10 Var   \n",
       "0      0.192699          0.140838  0.080168     0.0  0.039638  0.017862  \\\n",
       "1     -0.024363          0.123226 -0.008869    -1.0  0.035187  0.017930   \n",
       "2     -0.112892          0.026073 -0.014388     0.0  0.028830  0.014729   \n",
       "3     -0.060343         -0.059421 -0.014598     0.0  0.007641  0.011799   \n",
       "4     -0.112219          0.010391 -0.074901     0.0 -0.007263  0.008164   \n",
       "...         ...               ...       ...     ...       ...       ...   \n",
       "35379  0.322755         -0.076316  0.015833    -1.0  0.006766  0.004553   \n",
       "35380 -0.034564         -0.233618  0.000844    -1.0  0.006209  0.003724   \n",
       "35381  0.025090         -0.260223  0.000675    -1.0  0.003024  0.003342   \n",
       "35382  0.037882         -0.148241  0.007278    -1.0  0.005360  0.004051   \n",
       "35383 -0.070788          0.011799 -0.006221    -1.0  0.003627  0.003581   \n",
       "\n",
       "       Crossover_-1  Crossover_0  Crossover_1  Crossover  MA5 UP  MA10 UP  \n",
       "0               0.0          0.0          0.0          0       1        0  \n",
       "1               0.0          0.0          0.0         -1       1        0  \n",
       "2               0.0          0.0          0.0         -1       1        0  \n",
       "3               0.0          0.0          0.0         -1       1        0  \n",
       "4               0.0          0.0          0.0         -1       1        0  \n",
       "...             ...          ...          ...        ...     ...      ...  \n",
       "35379           0.0          1.0          0.0          0       1        0  \n",
       "35380           0.0          1.0          0.0          0       1        0  \n",
       "35381           0.0          1.0          0.0          0       1        0  \n",
       "35382           0.0          1.0          0.0         -1       1        0  \n",
       "35383           1.0          0.0          0.0         -1       1        0  \n",
       "\n",
       "[35384 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.593602\n",
       "False    0.406398\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_dummy = np.argmax(transition_predict_data[dummies.columns].values, axis=1)\n",
    "argmax_values = pd.Series(argmax_dummy) - 1\n",
    "(transition_predict_data['Crossover'] == argmax_values).value_counts() / argmax_values.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting regular model dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = range(round(0.7 * len(dataset)), round(0.9 * len(dataset)), int(seq_length / 5))\n",
    "val_indices = range(round(0.9 * len(dataset)), len(dataset) - seq_length)\n",
    "\n",
    "train_set = torch.utils.data.Subset(dataset, train_indices)\n",
    "# Validation set will be training set for Meta Labelling\n",
    "val_set = torch.utils.data.Subset(dataset, val_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       " 0.0    1566\n",
       "-1.0     631\n",
       " 1.0     161\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.2675996607294317, 0.6641221374045801, 0.06827820186598813]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_distribution = (transition_predict_data.loc[train_set.indices, 'Target'].value_counts(\n",
    ") / transition_predict_data.loc[train_set.indices, 'Target'].shape[0]).sort_index().to_list()\n",
    "display(transition_predict_data.loc[train_set.indices, 'Target'].value_counts())\n",
    "label_distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       " 0.0    1759\n",
       "-1.0    1325\n",
       " 1.0     438\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.37620670073821694, 0.4994321408290744, 0.12436115843270869]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_distribution = (transition_predict_data.loc[val_set.indices, 'Target'].value_counts(\n",
    ") / transition_predict_data.loc[val_set.indices, 'Target'].shape[0]).sort_index().to_list()\n",
    "display(transition_predict_data.loc[val_set.indices, 'Target'].value_counts())\n",
    "val_label_distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.736925515055468, 1.5057471264367817, 14.645962732919255]\n"
     ]
    }
   ],
   "source": [
    "class_weights = [1 / p for p in label_distribution]\n",
    "print(class_weights)\n",
    "weights = [class_weights[torch.argmax(label)] for _, label in train_set]\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=weights, num_samples=len(train_set), replacement=True)\n",
    "# train_sampler = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = lstm_model.input_size\n",
    "hidden_size = lstm_model.hidden_size\n",
    "batch_size = 64\n",
    "num_layers = lstm_model.num_layers\n",
    "output_size = transition_predict_data['Target'].unique().size\n",
    "new_lstm_model = LSTMModel(input_size, hidden_size,\n",
    "                       num_layers, output_size).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_lstm(lstm_model, val_set, len(val_set), num_layers, hidden_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60 -- [1998/2358 (100.0%)]\tLoss: 1.1035125803303074\tAccuracy: 0.345\tTime taken: 0.40625\tValidation Loss: 1.0869498252868652 || Validation Accuracy: 0.432\n",
      "Epoch: 2/60 -- [1998/2358 (100.0%)]\tLoss: 1.1027524954563863\tAccuracy: 0.335\tTime taken: 0.359375\tValidation Loss: 1.0876435041427612 || Validation Accuracy: 0.435\n",
      "Epoch: 3/60 -- [1998/2358 (100.0%)]\tLoss: 1.1015965390849758\tAccuracy: 0.336\tTime taken: 0.375\tValidation Loss: 1.0882160663604736 || Validation Accuracy: 0.445\n",
      "Epoch: 4/60 -- [1998/2358 (100.0%)]\tLoss: 1.0996199266330615\tAccuracy: 0.329\tTime taken: 0.546875\tValidation Loss: 1.0889683961868286 || Validation Accuracy: 0.452\n",
      "Epoch: 5/60 -- [1998/2358 (100.0%)]\tLoss: 1.0989999996649253\tAccuracy: 0.335\tTime taken: 0.421875\tValidation Loss: 1.0894832611083984 || Validation Accuracy: 0.455\n",
      "Epoch: 6/60 -- [1998/2358 (100.0%)]\tLoss: 1.0975281966699135\tAccuracy: 0.342\tTime taken: 0.5\tValidation Loss: 1.0898281335830688 || Validation Accuracy: 0.449\n",
      "Epoch: 7/60 -- [1998/2358 (100.0%)]\tLoss: 1.0980317334871035\tAccuracy: 0.338\tTime taken: 0.53125\tValidation Loss: 1.0913382768630981 || Validation Accuracy: 0.462\n",
      "Epoch: 8/60 -- [1998/2358 (100.0%)]\tLoss: 1.096760807810603\tAccuracy: 0.343\tTime taken: 0.625\tValidation Loss: 1.0933111906051636 || Validation Accuracy: 0.475\n",
      "Epoch: 9/60 -- [1998/2358 (100.0%)]\tLoss: 1.094642838916263\tAccuracy: 0.349\tTime taken: 0.453125\tValidation Loss: 1.0919857025146484 || Validation Accuracy: 0.428\n",
      "Epoch: 10/60 -- [1998/2358 (100.0%)]\tLoss: 1.0921493704254563\tAccuracy: 0.419\tTime taken: 0.421875\tValidation Loss: 1.094744086265564 || Validation Accuracy: 0.325\n",
      "Epoch: 11/60 -- [1998/2358 (100.0%)]\tLoss: 1.0856633411871421\tAccuracy: 0.405\tTime taken: 0.4375\tValidation Loss: 1.0993807315826416 || Validation Accuracy: 0.295\n",
      "Epoch: 12/60 -- [1998/2358 (100.0%)]\tLoss: 1.0808984911119617\tAccuracy: 0.403\tTime taken: 0.4375\tValidation Loss: 1.1031434535980225 || Validation Accuracy: 0.305\n",
      "Epoch: 13/60 -- [1998/2358 (100.0%)]\tLoss: 1.079243009154861\tAccuracy: 0.388\tTime taken: 0.4375\tValidation Loss: 1.0996713638305664 || Validation Accuracy: 0.319\n",
      "Epoch: 14/60 -- [1998/2358 (100.0%)]\tLoss: 1.0720000782528438\tAccuracy: 0.419\tTime taken: 0.4375\tValidation Loss: 1.09474515914917 || Validation Accuracy: 0.341\n",
      "Epoch: 15/60 -- [1998/2358 (100.0%)]\tLoss: 1.0639379926629968\tAccuracy: 0.428\tTime taken: 0.46875\tValidation Loss: 1.1034079790115356 || Validation Accuracy: 0.328\n",
      "Epoch: 16/60 -- [1998/2358 (100.0%)]\tLoss: 1.0644855048205402\tAccuracy: 0.416\tTime taken: 0.453125\tValidation Loss: 1.110839605331421 || Validation Accuracy: 0.307\n",
      "Epoch: 17/60 -- [1998/2358 (100.0%)]\tLoss: 1.0629471153826326\tAccuracy: 0.407\tTime taken: 0.46875\tValidation Loss: 1.1063979864120483 || Validation Accuracy: 0.318\n",
      "Epoch: 18/60 -- [1998/2358 (100.0%)]\tLoss: 1.0626411534644462\tAccuracy: 0.426\tTime taken: 0.4375\tValidation Loss: 1.0975165367126465 || Validation Accuracy: 0.340\n",
      "Epoch: 19/60 -- [1998/2358 (100.0%)]\tLoss: 1.0675591198173728\tAccuracy: 0.418\tTime taken: 0.421875\tValidation Loss: 1.096440315246582 || Validation Accuracy: 0.333\n",
      "Epoch: 20/60 -- [1998/2358 (100.0%)]\tLoss: 1.057789963644904\tAccuracy: 0.426\tTime taken: 0.453125\tValidation Loss: 1.0955828428268433 || Validation Accuracy: 0.335\n",
      "Epoch: 21/60 -- [1998/2358 (100.0%)]\tLoss: 1.0530537769601152\tAccuracy: 0.452\tTime taken: 0.4375\tValidation Loss: 1.1041632890701294 || Validation Accuracy: 0.334\n",
      "Epoch: 22/60 -- [1998/2358 (100.0%)]\tLoss: 1.0563101317431476\tAccuracy: 0.442\tTime taken: 0.4375\tValidation Loss: 1.1090121269226074 || Validation Accuracy: 0.328\n",
      "Epoch: 23/60 -- [1998/2358 (100.0%)]\tLoss: 1.0481929456865466\tAccuracy: 0.447\tTime taken: 0.4375\tValidation Loss: 1.088923454284668 || Validation Accuracy: 0.344\n",
      "Epoch: 24/60 -- [1998/2358 (100.0%)]\tLoss: 1.0433996529192537\tAccuracy: 0.446\tTime taken: 0.4375\tValidation Loss: 1.0866860151290894 || Validation Accuracy: 0.353\n",
      "Epoch: 25/60 -- [1998/2358 (100.0%)]\tLoss: 1.047333226010606\tAccuracy: 0.458\tTime taken: 0.4375\tValidation Loss: 1.0763747692108154 || Validation Accuracy: 0.369\n",
      "Epoch: 26/60 -- [1998/2358 (100.0%)]\tLoss: 1.042408688648327\tAccuracy: 0.455\tTime taken: 0.421875\tValidation Loss: 1.1163439750671387 || Validation Accuracy: 0.325\n",
      "Epoch: 27/60 -- [1998/2358 (100.0%)]\tLoss: 1.0378619029715255\tAccuracy: 0.461\tTime taken: 0.4375\tValidation Loss: 1.0947039127349854 || Validation Accuracy: 0.353\n",
      "Epoch: 28/60 -- [1998/2358 (100.0%)]\tLoss: 1.04803282989038\tAccuracy: 0.453\tTime taken: 0.421875\tValidation Loss: 1.0997438430786133 || Validation Accuracy: 0.358\n",
      "Epoch: 29/60 -- [1998/2358 (100.0%)]\tLoss: 1.0322108945331059\tAccuracy: 0.458\tTime taken: 0.5\tValidation Loss: 1.0853632688522339 || Validation Accuracy: 0.378\n",
      "Epoch: 30/60 -- [1998/2358 (100.0%)]\tLoss: 1.0369529063637193\tAccuracy: 0.470\tTime taken: 0.484375\tValidation Loss: 1.0879970788955688 || Validation Accuracy: 0.366\n",
      "Epoch: 31/60 -- [1998/2358 (100.0%)]\tLoss: 1.0349283186165061\tAccuracy: 0.464\tTime taken: 0.4375\tValidation Loss: 1.0945534706115723 || Validation Accuracy: 0.365\n",
      "Epoch: 32/60 -- [1998/2358 (100.0%)]\tLoss: 1.035492172112336\tAccuracy: 0.466\tTime taken: 0.421875\tValidation Loss: 1.101967692375183 || Validation Accuracy: 0.354\n",
      "Epoch: 33/60 -- [1998/2358 (100.0%)]\tLoss: 1.0386268270982277\tAccuracy: 0.453\tTime taken: 0.4375\tValidation Loss: 1.1048016548156738 || Validation Accuracy: 0.346\n",
      "Epoch: 34/60 -- [1998/2358 (100.0%)]\tLoss: 1.0305017748394527\tAccuracy: 0.481\tTime taken: 0.4375\tValidation Loss: 1.0859458446502686 || Validation Accuracy: 0.378\n",
      "Epoch: 35/60 -- [1998/2358 (100.0%)]\tLoss: 1.0291829270285529\tAccuracy: 0.491\tTime taken: 0.453125\tValidation Loss: 1.1050060987472534 || Validation Accuracy: 0.344\n",
      "Epoch: 36/60 -- [1998/2358 (100.0%)]\tLoss: 1.0164774624077049\tAccuracy: 0.520\tTime taken: 0.4375\tValidation Loss: 1.0772581100463867 || Validation Accuracy: 0.396\n",
      "Epoch: 37/60 -- [1998/2358 (100.0%)]\tLoss: 1.022626197015917\tAccuracy: 0.489\tTime taken: 0.4375\tValidation Loss: 1.0888032913208008 || Validation Accuracy: 0.375\n",
      "Epoch: 38/60 -- [1998/2358 (100.0%)]\tLoss: 1.0229348137572005\tAccuracy: 0.489\tTime taken: 0.4375\tValidation Loss: 1.0900418758392334 || Validation Accuracy: 0.381\n",
      "Epoch: 39/60 -- [1998/2358 (100.0%)]\tLoss: 1.007338206510286\tAccuracy: 0.508\tTime taken: 0.4375\tValidation Loss: 1.0977249145507812 || Validation Accuracy: 0.358\n",
      "Epoch: 40/60 -- [1998/2358 (100.0%)]\tLoss: 1.0103116824820235\tAccuracy: 0.505\tTime taken: 0.421875\tValidation Loss: 1.1050766706466675 || Validation Accuracy: 0.346\n",
      "Epoch: 41/60 -- [1998/2358 (100.0%)]\tLoss: 1.011279019149574\tAccuracy: 0.501\tTime taken: 0.453125\tValidation Loss: 1.0926406383514404 || Validation Accuracy: 0.367\n",
      "Epoch: 42/60 -- [1998/2358 (100.0%)]\tLoss: 1.01320817180582\tAccuracy: 0.510\tTime taken: 0.421875\tValidation Loss: 1.108541488647461 || Validation Accuracy: 0.350\n",
      "Epoch: 43/60 -- [1998/2358 (100.0%)]\tLoss: 1.0030798525423616\tAccuracy: 0.520\tTime taken: 0.4375\tValidation Loss: 1.1320396661758423 || Validation Accuracy: 0.325\n",
      "Epoch: 44/60 -- [1998/2358 (100.0%)]\tLoss: 1.020885957253946\tAccuracy: 0.484\tTime taken: 0.46875\tValidation Loss: 1.0991528034210205 || Validation Accuracy: 0.356\n",
      "Epoch: 45/60 -- [1998/2358 (100.0%)]\tLoss: 1.0117830634117126\tAccuracy: 0.486\tTime taken: 0.375\tValidation Loss: 1.0843852758407593 || Validation Accuracy: 0.376\n",
      "Epoch: 46/60 -- [1998/2358 (100.0%)]\tLoss: 0.9930426526714016\tAccuracy: 0.517\tTime taken: 0.375\tValidation Loss: 1.1082749366760254 || Validation Accuracy: 0.350\n",
      "Epoch: 47/60 -- [1998/2358 (100.0%)]\tLoss: 0.9996372541865787\tAccuracy: 0.525\tTime taken: 0.375\tValidation Loss: 1.089672565460205 || Validation Accuracy: 0.376\n",
      "Epoch: 48/60 -- [1998/2358 (100.0%)]\tLoss: 0.9993345753566639\tAccuracy: 0.522\tTime taken: 0.375\tValidation Loss: 1.108932375907898 || Validation Accuracy: 0.352\n",
      "Epoch: 49/60 -- [1998/2358 (100.0%)]\tLoss: 1.0013969476158555\tAccuracy: 0.508\tTime taken: 0.359375\tValidation Loss: 1.0759257078170776 || Validation Accuracy: 0.384\n",
      "Epoch: 50/60 -- [1998/2358 (100.0%)]\tLoss: 0.9980967318689501\tAccuracy: 0.514\tTime taken: 0.390625\tValidation Loss: 1.087491750717163 || Validation Accuracy: 0.370\n",
      "Epoch: 51/60 -- [1998/2358 (100.0%)]\tLoss: 1.005270540714264\tAccuracy: 0.510\tTime taken: 0.421875\tValidation Loss: 1.1068953275680542 || Validation Accuracy: 0.355\n",
      "Epoch: 52/60 -- [1998/2358 (100.0%)]\tLoss: 0.9904491095929533\tAccuracy: 0.535\tTime taken: 0.4375\tValidation Loss: 1.1036690473556519 || Validation Accuracy: 0.367\n",
      "Epoch: 53/60 -- [1998/2358 (100.0%)]\tLoss: 0.9970674981942048\tAccuracy: 0.529\tTime taken: 0.4375\tValidation Loss: 1.0863995552062988 || Validation Accuracy: 0.374\n",
      "Epoch: 54/60 -- [1998/2358 (100.0%)]\tLoss: 0.9943075357256709\tAccuracy: 0.535\tTime taken: 0.4375\tValidation Loss: 1.1291970014572144 || Validation Accuracy: 0.332\n",
      "Epoch: 55/60 -- [1998/2358 (100.0%)]\tLoss: 0.9927583836220406\tAccuracy: 0.531\tTime taken: 0.453125\tValidation Loss: 1.09261155128479 || Validation Accuracy: 0.375\n",
      "Epoch: 56/60 -- [1998/2358 (100.0%)]\tLoss: 0.9871962183230633\tAccuracy: 0.534\tTime taken: 0.4375\tValidation Loss: 1.0844796895980835 || Validation Accuracy: 0.370\n",
      "Epoch: 57/60 -- [1998/2358 (100.0%)]\tLoss: 0.9850320091118684\tAccuracy: 0.552\tTime taken: 0.421875\tValidation Loss: 1.1033716201782227 || Validation Accuracy: 0.363\n",
      "Epoch: 58/60 -- [1998/2358 (100.0%)]\tLoss: 0.9906787920642544\tAccuracy: 0.535\tTime taken: 0.4375\tValidation Loss: 1.1096727848052979 || Validation Accuracy: 0.361\n",
      "Epoch: 59/60 -- [1998/2358 (100.0%)]\tLoss: 0.9899218404615248\tAccuracy: 0.531\tTime taken: 0.4375\tValidation Loss: 1.103499412536621 || Validation Accuracy: 0.376\n",
      "Epoch: 60/60 -- [1998/2358 (100.0%)]\tLoss: 0.9740708985844174\tAccuracy: 0.562\tTime taken: 0.4375\tValidation Loss: 1.1105480194091797 || Validation Accuracy: 0.371\n",
      "Best accuracy : 0.4750141964792731 || Best confusion matrix : \n",
      " [[2.73e+02 1.04e+03 0.00e+00]\n",
      " [3.63e+02 1.40e+03 1.00e+00]\n",
      " [9.40e+01 3.51e+02 0.00e+00]]\n",
      "Last confusion matrix : \n",
      " [[371. 537. 405.]\n",
      " [498. 782. 484.]\n",
      " [135. 158. 152.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.1035125803303074,\n",
       "  1.1027524954563863,\n",
       "  1.1015965390849758,\n",
       "  1.0996199266330615,\n",
       "  1.0989999996649253,\n",
       "  1.0975281966699135,\n",
       "  1.0980317334871035,\n",
       "  1.096760807810603,\n",
       "  1.094642838916263,\n",
       "  1.0921493704254563,\n",
       "  1.0856633411871421,\n",
       "  1.0808984911119617,\n",
       "  1.079243009154861,\n",
       "  1.0720000782528438,\n",
       "  1.0639379926629968,\n",
       "  1.0644855048205402,\n",
       "  1.0629471153826326,\n",
       "  1.0626411534644462,\n",
       "  1.0675591198173728,\n",
       "  1.057789963644904,\n",
       "  1.0530537769601152,\n",
       "  1.0563101317431476,\n",
       "  1.0481929456865466,\n",
       "  1.0433996529192537,\n",
       "  1.047333226010606,\n",
       "  1.042408688648327,\n",
       "  1.0378619029715255,\n",
       "  1.04803282989038,\n",
       "  1.0322108945331059,\n",
       "  1.0369529063637193,\n",
       "  1.0349283186165061,\n",
       "  1.035492172112336,\n",
       "  1.0386268270982277,\n",
       "  1.0305017748394527,\n",
       "  1.0291829270285529,\n",
       "  1.0164774624077049,\n",
       "  1.022626197015917,\n",
       "  1.0229348137572005,\n",
       "  1.007338206510286,\n",
       "  1.0103116824820235,\n",
       "  1.011279019149574,\n",
       "  1.01320817180582,\n",
       "  1.0030798525423616,\n",
       "  1.020885957253946,\n",
       "  1.0117830634117126,\n",
       "  0.9930426526714016,\n",
       "  0.9996372541865787,\n",
       "  0.9993345753566639,\n",
       "  1.0013969476158555,\n",
       "  0.9980967318689501,\n",
       "  1.005270540714264,\n",
       "  0.9904491095929533,\n",
       "  0.9970674981942048,\n",
       "  0.9943075357256709,\n",
       "  0.9927583836220406,\n",
       "  0.9871962183230633,\n",
       "  0.9850320091118684,\n",
       "  0.9906787920642544,\n",
       "  0.9899218404615248,\n",
       "  0.9740708985844174],\n",
       " [0.3452078032230704,\n",
       "  0.33502968617472434,\n",
       "  0.3363019508057676,\n",
       "  0.3286683630195081,\n",
       "  0.3346055979643766,\n",
       "  0.3422391857506361,\n",
       "  0.3375742154368109,\n",
       "  0.3426632739609839,\n",
       "  0.3486005089058524,\n",
       "  0.41857506361323155,\n",
       "  0.40500424088210346,\n",
       "  0.4033078880407125,\n",
       "  0.38761662425784565,\n",
       "  0.41942324003392706,\n",
       "  0.4279050042408821,\n",
       "  0.4164546225614928,\n",
       "  0.4071246819338422,\n",
       "  0.4257845631891433,\n",
       "  0.41772688719253603,\n",
       "  0.4257845631891433,\n",
       "  0.45165394402035625,\n",
       "  0.44189991518235794,\n",
       "  0.4474130619168787,\n",
       "  0.4457167090754877,\n",
       "  0.4575911789652248,\n",
       "  0.4546225614927905,\n",
       "  0.46098388464800677,\n",
       "  0.45250212044105176,\n",
       "  0.4584393553859203,\n",
       "  0.46988973706530957,\n",
       "  0.4643765903307888,\n",
       "  0.4660729431721798,\n",
       "  0.45335029686174727,\n",
       "  0.4813401187446989,\n",
       "  0.4910941475826972,\n",
       "  0.5199321458863444,\n",
       "  0.48897370653095845,\n",
       "  0.48897370653095845,\n",
       "  0.508481764206955,\n",
       "  0.5050890585241731,\n",
       "  0.5012722646310432,\n",
       "  0.510178117048346,\n",
       "  0.5195080576759966,\n",
       "  0.48430873621713316,\n",
       "  0.4864291772688719,\n",
       "  0.5165394402035624,\n",
       "  0.5245971162001697,\n",
       "  0.5220525869380831,\n",
       "  0.508481764206955,\n",
       "  0.5144189991518235,\n",
       "  0.5097540288379983,\n",
       "  0.5351993214588634,\n",
       "  0.5292620865139949,\n",
       "  0.5351993214588634,\n",
       "  0.5309584393553859,\n",
       "  0.5343511450381679,\n",
       "  0.5521628498727735,\n",
       "  0.5351993214588634,\n",
       "  0.5313825275657337,\n",
       "  0.5619168787107719],\n",
       " [tensor(1.0869, device='cuda:0'),\n",
       "  tensor(1.0876, device='cuda:0'),\n",
       "  tensor(1.0882, device='cuda:0'),\n",
       "  tensor(1.0890, device='cuda:0'),\n",
       "  tensor(1.0895, device='cuda:0'),\n",
       "  tensor(1.0898, device='cuda:0'),\n",
       "  tensor(1.0913, device='cuda:0'),\n",
       "  tensor(1.0933, device='cuda:0'),\n",
       "  tensor(1.0920, device='cuda:0'),\n",
       "  tensor(1.0947, device='cuda:0'),\n",
       "  tensor(1.0994, device='cuda:0'),\n",
       "  tensor(1.1031, device='cuda:0'),\n",
       "  tensor(1.0997, device='cuda:0'),\n",
       "  tensor(1.0947, device='cuda:0'),\n",
       "  tensor(1.1034, device='cuda:0'),\n",
       "  tensor(1.1108, device='cuda:0'),\n",
       "  tensor(1.1064, device='cuda:0'),\n",
       "  tensor(1.0975, device='cuda:0'),\n",
       "  tensor(1.0964, device='cuda:0'),\n",
       "  tensor(1.0956, device='cuda:0'),\n",
       "  tensor(1.1042, device='cuda:0'),\n",
       "  tensor(1.1090, device='cuda:0'),\n",
       "  tensor(1.0889, device='cuda:0'),\n",
       "  tensor(1.0867, device='cuda:0'),\n",
       "  tensor(1.0764, device='cuda:0'),\n",
       "  tensor(1.1163, device='cuda:0'),\n",
       "  tensor(1.0947, device='cuda:0'),\n",
       "  tensor(1.0997, device='cuda:0'),\n",
       "  tensor(1.0854, device='cuda:0'),\n",
       "  tensor(1.0880, device='cuda:0'),\n",
       "  tensor(1.0946, device='cuda:0'),\n",
       "  tensor(1.1020, device='cuda:0'),\n",
       "  tensor(1.1048, device='cuda:0'),\n",
       "  tensor(1.0859, device='cuda:0'),\n",
       "  tensor(1.1050, device='cuda:0'),\n",
       "  tensor(1.0773, device='cuda:0'),\n",
       "  tensor(1.0888, device='cuda:0'),\n",
       "  tensor(1.0900, device='cuda:0'),\n",
       "  tensor(1.0977, device='cuda:0'),\n",
       "  tensor(1.1051, device='cuda:0'),\n",
       "  tensor(1.0926, device='cuda:0'),\n",
       "  tensor(1.1085, device='cuda:0'),\n",
       "  tensor(1.1320, device='cuda:0'),\n",
       "  tensor(1.0992, device='cuda:0'),\n",
       "  tensor(1.0844, device='cuda:0'),\n",
       "  tensor(1.1083, device='cuda:0'),\n",
       "  tensor(1.0897, device='cuda:0'),\n",
       "  tensor(1.1089, device='cuda:0'),\n",
       "  tensor(1.0759, device='cuda:0'),\n",
       "  tensor(1.0875, device='cuda:0'),\n",
       "  tensor(1.1069, device='cuda:0'),\n",
       "  tensor(1.1037, device='cuda:0'),\n",
       "  tensor(1.0864, device='cuda:0'),\n",
       "  tensor(1.1292, device='cuda:0'),\n",
       "  tensor(1.0926, device='cuda:0'),\n",
       "  tensor(1.0845, device='cuda:0'),\n",
       "  tensor(1.1034, device='cuda:0'),\n",
       "  tensor(1.1097, device='cuda:0'),\n",
       "  tensor(1.1035, device='cuda:0'),\n",
       "  tensor(1.1105, device='cuda:0')],\n",
       " [0.43157296990346394,\n",
       "  0.4349801249290176,\n",
       "  0.444633730834753,\n",
       "  0.45229982964224874,\n",
       "  0.4554230550823396,\n",
       "  0.4494605337876207,\n",
       "  0.4619534355479841,\n",
       "  0.4750141964792731,\n",
       "  0.42759795570698467,\n",
       "  0.32481544576944915,\n",
       "  0.29528676888131744,\n",
       "  0.3049403747870528,\n",
       "  0.3188529244747303,\n",
       "  0.34128336172629187,\n",
       "  0.32793867120954,\n",
       "  0.30721181147075527,\n",
       "  0.31771720613287907,\n",
       "  0.34014764338444065,\n",
       "  0.3333333333333333,\n",
       "  0.33503691084611015,\n",
       "  0.3339011925042589,\n",
       "  0.32793867120954,\n",
       "  0.3438387279954571,\n",
       "  0.3529244747302669,\n",
       "  0.3693923906871096,\n",
       "  0.32481544576944915,\n",
       "  0.3529244747302669,\n",
       "  0.3577512776831346,\n",
       "  0.37762634866553096,\n",
       "  0.36626916524701875,\n",
       "  0.3648495173197047,\n",
       "  0.3537762634866553,\n",
       "  0.34639409426462237,\n",
       "  0.37791027825099377,\n",
       "  0.3444065871663827,\n",
       "  0.39636570130607607,\n",
       "  0.3750709823963657,\n",
       "  0.3807495741056218,\n",
       "  0.3580352072685974,\n",
       "  0.34582623509369675,\n",
       "  0.36683702441794436,\n",
       "  0.3495173197047132,\n",
       "  0.32453151618398635,\n",
       "  0.35633162975582056,\n",
       "  0.37592277115275413,\n",
       "  0.34980124929017603,\n",
       "  0.37649063032367974,\n",
       "  0.3523566155593413,\n",
       "  0.3835888699602499,\n",
       "  0.3696763202725724,\n",
       "  0.35547984099943214,\n",
       "  0.36683702441794436,\n",
       "  0.3739352640545145,\n",
       "  0.3319136854060193,\n",
       "  0.3750709823963657,\n",
       "  0.3696763202725724,\n",
       "  0.3625780806360023,\n",
       "  0.36144236229415105,\n",
       "  0.3756388415672913,\n",
       "  0.37052810902896083],\n",
       " array([[2.73e+02, 1.04e+03, 0.00e+00],\n",
       "        [3.63e+02, 1.40e+03, 1.00e+00],\n",
       "        [9.40e+01, 3.51e+02, 0.00e+00]]),\n",
       " 0.4750141964792731)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.Tensor(label_distribution).to(device)\n",
    "train_lstm(lstm_model, train_set, val_set, 60, 0.0001,\n",
    "           batch_size, lstm_model.num_layers, lstm_model.hidden_size, device, train_sampler, class_weights=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating sampler mid training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m class_weights \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(class_weights)\n\u001b[1;32m----> 3\u001b[0m weights \u001b[39m=\u001b[39m [class_weights[torch\u001b[39m.\u001b[39margmax(label)] \u001b[39mfor\u001b[39;00m _, label \u001b[39min\u001b[39;00m train_set]\n\u001b[0;32m      4\u001b[0m train_sampler \u001b[39m=\u001b[39m WeightedRandomSampler(\n\u001b[0;32m      5\u001b[0m     weights\u001b[39m=\u001b[39mweights, num_samples\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_set), replacement\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m class_weights \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(class_weights)\n\u001b[1;32m----> 3\u001b[0m weights \u001b[39m=\u001b[39m [class_weights[torch\u001b[39m.\u001b[39;49margmax(label)] \u001b[39mfor\u001b[39;00m _, label \u001b[39min\u001b[39;00m train_set]\n\u001b[0;32m      4\u001b[0m train_sampler \u001b[39m=\u001b[39m WeightedRandomSampler(\n\u001b[0;32m      5\u001b[0m     weights\u001b[39m=\u001b[39mweights, num_samples\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_set), replacement\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class_weights = []\n",
    "print(class_weights)\n",
    "weights = [class_weights[torch.argmax(label)] for _, label in train_set]\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=weights, num_samples=len(train_set), replacement=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
