{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"minute_data/BTC-USD_1M_SIGNALS.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>-DM</th>\n",
       "      <th>+DM</th>\n",
       "      <th>ADX14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764620</td>\n",
       "      <td>2017-12-31 23:57:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13908.73</td>\n",
       "      <td>13913.26</td>\n",
       "      <td>13874.99</td>\n",
       "      <td>13913.26</td>\n",
       "      <td>-0.295570</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>2.660454</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.363161</td>\n",
       "      <td>0.229565</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>3.398648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764560</td>\n",
       "      <td>2017-12-31 23:56:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13827.00</td>\n",
       "      <td>13908.69</td>\n",
       "      <td>13827.00</td>\n",
       "      <td>13859.58</td>\n",
       "      <td>-0.303185</td>\n",
       "      <td>-0.684081</td>\n",
       "      <td>0.796397</td>\n",
       "      <td>0.087233</td>\n",
       "      <td>0.089257</td>\n",
       "      <td>2.307135</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>3.398648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514764500</td>\n",
       "      <td>2017-12-31 23:55:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>-0.344218</td>\n",
       "      <td>-0.442047</td>\n",
       "      <td>-0.293868</td>\n",
       "      <td>-0.036330</td>\n",
       "      <td>-0.255116</td>\n",
       "      <td>-0.190940</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>3.398648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1514764440</td>\n",
       "      <td>2017-12-31 23:54:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13884.14</td>\n",
       "      <td>13884.14</td>\n",
       "      <td>13823.88</td>\n",
       "      <td>13854.28</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.373551</td>\n",
       "      <td>-0.691035</td>\n",
       "      <td>-0.079503</td>\n",
       "      <td>-0.318178</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>1.710867</td>\n",
       "      <td>3.398648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1514764380</td>\n",
       "      <td>2017-12-31 23:53:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13854.52</td>\n",
       "      <td>13898.70</td>\n",
       "      <td>13840.85</td>\n",
       "      <td>13884.15</td>\n",
       "      <td>0.367259</td>\n",
       "      <td>0.380942</td>\n",
       "      <td>-0.266264</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>3.398648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675129</th>\n",
       "      <td>1609459500</td>\n",
       "      <td>2021-01-01 00:05:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29021.86</td>\n",
       "      <td>29023.38</td>\n",
       "      <td>28982.33</td>\n",
       "      <td>28999.50</td>\n",
       "      <td>-0.196942</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.659112</td>\n",
       "      <td>0.156727</td>\n",
       "      <td>1.550490</td>\n",
       "      <td>0.483496</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-3.784359e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675130</th>\n",
       "      <td>1609459440</td>\n",
       "      <td>2021-01-01 00:04:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29048.13</td>\n",
       "      <td>29057.73</td>\n",
       "      <td>29035.61</td>\n",
       "      <td>29045.19</td>\n",
       "      <td>-0.141744</td>\n",
       "      <td>0.278150</td>\n",
       "      <td>1.064047</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>1.726775</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.926236</td>\n",
       "      <td>-4.489000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675131</th>\n",
       "      <td>1609459380</td>\n",
       "      <td>2021-01-01 00:03:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29037.68</td>\n",
       "      <td>29069.39</td>\n",
       "      <td>29019.00</td>\n",
       "      <td>29048.13</td>\n",
       "      <td>-0.035411</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>1.176341</td>\n",
       "      <td>0.486452</td>\n",
       "      <td>1.766349</td>\n",
       "      <td>0.604494</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-5.712855e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675132</th>\n",
       "      <td>1609459320</td>\n",
       "      <td>2021-01-01 00:02:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29069.80</td>\n",
       "      <td>29073.02</td>\n",
       "      <td>29028.14</td>\n",
       "      <td>29035.89</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>-0.075473</td>\n",
       "      <td>1.032994</td>\n",
       "      <td>0.572733</td>\n",
       "      <td>1.641080</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>-0.048052</td>\n",
       "      <td>-6.535419e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675133</th>\n",
       "      <td>1609459260</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29007.31</td>\n",
       "      <td>29086.90</td>\n",
       "      <td>29007.31</td>\n",
       "      <td>29083.47</td>\n",
       "      <td>1.737225</td>\n",
       "      <td>0.289327</td>\n",
       "      <td>1.957091</td>\n",
       "      <td>0.720446</td>\n",
       "      <td>1.703201</td>\n",
       "      <td>0.833466</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-7.252311e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675134 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unix                 Date   Symbol      Open      High  \\\n",
       "0        1514764620  2017-12-31 23:57:00  BTC/USD  13908.73  13913.26   \n",
       "1        1514764560  2017-12-31 23:56:00  BTC/USD  13827.00  13908.69   \n",
       "2        1514764500  2017-12-31 23:55:00  BTC/USD  13825.05  13825.05   \n",
       "3        1514764440  2017-12-31 23:54:00  BTC/USD  13884.14  13884.14   \n",
       "4        1514764380  2017-12-31 23:53:00  BTC/USD  13854.52  13898.70   \n",
       "...             ...                  ...      ...       ...       ...   \n",
       "2675129  1609459500  2021-01-01 00:05:00  BTC/USD  29021.86  29023.38   \n",
       "2675130  1609459440  2021-01-01 00:04:00  BTC/USD  29048.13  29057.73   \n",
       "2675131  1609459380  2021-01-01 00:03:00  BTC/USD  29037.68  29069.39   \n",
       "2675132  1609459320  2021-01-01 00:02:00  BTC/USD  29069.80  29073.02   \n",
       "2675133  1609459260  2021-01-01 00:01:00  BTC/USD  29007.31  29086.90   \n",
       "\n",
       "              Low     Close  Volume USD  Variation       RSI      MACD  \\\n",
       "0        13874.99  13913.26   -0.295570  -0.514960  2.660454  0.163399   \n",
       "1        13827.00  13859.58   -0.303185  -0.684081  0.796397  0.087233   \n",
       "2        13825.05  13825.05   -0.344218  -0.442047 -0.293868 -0.036330   \n",
       "3        13823.88  13854.28   -0.020416   0.373551 -0.691035 -0.079503   \n",
       "4        13840.85  13884.15    0.367259   0.380942 -0.266264 -0.058034   \n",
       "...           ...       ...         ...        ...       ...       ...   \n",
       "2675129  28982.33  28999.50   -0.196942   0.012214  0.659112  0.156727   \n",
       "2675130  29035.61  29045.19   -0.141744   0.278150  1.064047  0.340786   \n",
       "2675131  29019.00  29048.13   -0.035411   0.017070  1.176341  0.486452   \n",
       "2675132  29028.14  29035.89    0.084682  -0.075473  1.032994  0.572733   \n",
       "2675133  29007.31  29083.47    1.737225   0.289327  1.957091  0.720446   \n",
       "\n",
       "           MACD_H       -DM       +DM         ADX14  \n",
       "0        0.363161  0.229565 -0.163178  3.398648e-14  \n",
       "1        0.089257  2.307135 -0.163178  3.398648e-14  \n",
       "2       -0.255116 -0.190940 -0.163178  3.398648e-14  \n",
       "3       -0.318178 -0.296745  1.710867  3.398648e-14  \n",
       "4       -0.197810 -0.296745  0.298594  3.398648e-14  \n",
       "...           ...       ...       ...           ...  \n",
       "2675129  1.550490  0.483496 -0.163178 -3.784359e-01  \n",
       "2675130  1.726775 -0.296745  0.926236 -4.489000e-01  \n",
       "2675131  1.766349  0.604494 -0.163178 -5.712855e-01  \n",
       "2675132  1.641080 -0.296745 -0.048052 -6.535419e-01  \n",
       "2675133  1.703201  0.833466 -0.163178 -7.252311e-01  \n",
       "\n",
       "[2675134 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = data.copy().drop([\"Open\",\"Close\",\"High\",\"Low\", \"Symbol\"],axis=1)\n",
    "max_days = 5\n",
    "target_range = 2\n",
    "for i in range(1,max_days):#2jours\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\"]].shift(i)\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i), \"ADX-{}\".format(i), \"+DM-{}\".format(i), \"-DM-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\",\"ADX14\",\"+DM\",\"-DM\"]].shift(i)\n",
    "    predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i)]] = data[[\"Variation\",\"Volume USD\",\"RSI\",\"MACD\",\"MACD_H\"]].shift(i)\n",
    "#predict_data[\"Target\"] = (data[\"Variation\"].shift(-1) >= 0)\n",
    "predict_data[\"Target\"] = (data[\"Close\"].shift(-target_range) - data[\"Close\"] >= 0)\n",
    "predict_data[\"Target\"] = np.where(predict_data[\"Target\"] == True, 1, 0)\n",
    "predict_data.dropna(inplace=True)\n",
    "predict_data.reset_index(inplace=True,drop=True)\n",
    "predict_data = predict_data[0:len(predict_data)-target_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = predict_data[[i % int(max_days) == 0 for i in range(len(predict_data))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>-DM</th>\n",
       "      <th>+DM</th>\n",
       "      <th>ADX14</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol-3</th>\n",
       "      <th>RSI-3</th>\n",
       "      <th>MACD-3</th>\n",
       "      <th>MACD_H-3</th>\n",
       "      <th>Variation-4</th>\n",
       "      <th>Vol-4</th>\n",
       "      <th>RSI-4</th>\n",
       "      <th>MACD-4</th>\n",
       "      <th>MACD_H-4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764380</td>\n",
       "      <td>2017-12-31 23:53:00</td>\n",
       "      <td>0.367259</td>\n",
       "      <td>0.380942</td>\n",
       "      <td>-0.266264</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>3.398648e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303185</td>\n",
       "      <td>0.796397</td>\n",
       "      <td>0.087233</td>\n",
       "      <td>0.089257</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>-0.295570</td>\n",
       "      <td>2.660454</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.363161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514764260</td>\n",
       "      <td>2017-12-31 23:51:00</td>\n",
       "      <td>-0.307925</td>\n",
       "      <td>0.022998</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.051013</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.753071</td>\n",
       "      <td>3.398648e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>-0.691035</td>\n",
       "      <td>-0.079503</td>\n",
       "      <td>-0.318178</td>\n",
       "      <td>-0.442047</td>\n",
       "      <td>-0.344218</td>\n",
       "      <td>-0.293868</td>\n",
       "      <td>-0.036330</td>\n",
       "      <td>-0.255116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1514764140</td>\n",
       "      <td>2017-12-31 23:49:00</td>\n",
       "      <td>-0.131674</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.432820</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.311280</td>\n",
       "      <td>3.398648e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140478</td>\n",
       "      <td>0.068701</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.116987</td>\n",
       "      <td>0.380942</td>\n",
       "      <td>0.367259</td>\n",
       "      <td>-0.266264</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1514764020</td>\n",
       "      <td>2017-12-31 23:47:00</td>\n",
       "      <td>-0.348619</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>0.536837</td>\n",
       "      <td>0.273205</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>3.398648e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309888</td>\n",
       "      <td>0.076674</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>0.022998</td>\n",
       "      <td>-0.307925</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.051013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1514763900</td>\n",
       "      <td>2017-12-31 23:45:00</td>\n",
       "      <td>-0.322627</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>0.343099</td>\n",
       "      <td>0.251670</td>\n",
       "      <td>0.320053</td>\n",
       "      <td>-0.242486</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>3.398648e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067075</td>\n",
       "      <td>0.433254</td>\n",
       "      <td>0.213927</td>\n",
       "      <td>0.486277</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.131674</td>\n",
       "      <td>0.432820</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675118</th>\n",
       "      <td>1609459920</td>\n",
       "      <td>2021-01-01 00:12:00</td>\n",
       "      <td>-0.123238</td>\n",
       "      <td>0.541444</td>\n",
       "      <td>-0.097895</td>\n",
       "      <td>-0.822243</td>\n",
       "      <td>0.166855</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.905304</td>\n",
       "      <td>3.879120e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144609</td>\n",
       "      <td>-0.599621</td>\n",
       "      <td>-0.852356</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>-0.183870</td>\n",
       "      <td>-0.424827</td>\n",
       "      <td>-0.774573</td>\n",
       "      <td>0.312876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675120</th>\n",
       "      <td>1609459800</td>\n",
       "      <td>2021-01-01 00:10:00</td>\n",
       "      <td>-0.139513</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>-0.591698</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.116549</td>\n",
       "      <td>4.157917e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.640388</td>\n",
       "      <td>-0.715009</td>\n",
       "      <td>-0.946685</td>\n",
       "      <td>-0.202488</td>\n",
       "      <td>0.056217</td>\n",
       "      <td>1.563090</td>\n",
       "      <td>-0.454848</td>\n",
       "      <td>-0.886675</td>\n",
       "      <td>-0.054885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675122</th>\n",
       "      <td>1609459680</td>\n",
       "      <td>2021-01-01 00:08:00</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>0.340013</td>\n",
       "      <td>-0.326229</td>\n",
       "      <td>1.055277</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>5.271002e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059105</td>\n",
       "      <td>-0.233153</td>\n",
       "      <td>-0.735235</td>\n",
       "      <td>0.363404</td>\n",
       "      <td>0.541444</td>\n",
       "      <td>-0.123238</td>\n",
       "      <td>-0.097895</td>\n",
       "      <td>-0.822243</td>\n",
       "      <td>0.166855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675124</th>\n",
       "      <td>1609459560</td>\n",
       "      <td>2021-01-01 00:06:00</td>\n",
       "      <td>-0.082574</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>1.062017</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>1.505349</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.265610</td>\n",
       "      <td>-2.630277e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010583</td>\n",
       "      <td>0.128702</td>\n",
       "      <td>-0.449689</td>\n",
       "      <td>0.911287</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>-0.139513</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>-0.591698</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675126</th>\n",
       "      <td>1609459440</td>\n",
       "      <td>2021-01-01 00:04:00</td>\n",
       "      <td>-0.141744</td>\n",
       "      <td>0.278150</td>\n",
       "      <td>1.064047</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>1.726775</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.926236</td>\n",
       "      <td>-4.489000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148565</td>\n",
       "      <td>0.836063</td>\n",
       "      <td>-0.136921</td>\n",
       "      <td>1.344475</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.340013</td>\n",
       "      <td>-0.326229</td>\n",
       "      <td>1.055277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1337564 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unix                 Date  Volume USD  Variation       RSI  \\\n",
       "0        1514764380  2017-12-31 23:53:00    0.367259   0.380942 -0.266264   \n",
       "2        1514764260  2017-12-31 23:51:00   -0.307925   0.022998  0.058271   \n",
       "4        1514764140  2017-12-31 23:49:00   -0.131674  -0.000092  0.432820   \n",
       "6        1514764020  2017-12-31 23:47:00   -0.348619  -0.010254  0.536837   \n",
       "8        1514763900  2017-12-31 23:45:00   -0.322627   0.521257  0.343099   \n",
       "...             ...                  ...         ...        ...       ...   \n",
       "2675118  1609459920  2021-01-01 00:12:00   -0.123238   0.541444 -0.097895   \n",
       "2675120  1609459800  2021-01-01 00:10:00   -0.139513   0.224667  0.126447   \n",
       "2675122  1609459680  2021-01-01 00:08:00   -0.025056   0.022950  0.340013   \n",
       "2675124  1609459560  2021-01-01 00:06:00   -0.082574   0.041965  1.062017   \n",
       "2675126  1609459440  2021-01-01 00:04:00   -0.141744   0.278150  1.064047   \n",
       "\n",
       "             MACD    MACD_H       -DM       +DM         ADX14  ...     Vol-3  \\\n",
       "0       -0.058034 -0.197810 -0.296745  0.298594  3.398648e-14  ... -0.303185   \n",
       "2       -0.026308 -0.051013 -0.296745  0.753071  3.398648e-14  ... -0.020416   \n",
       "4        0.133421  0.341924 -0.296745  0.311280  3.398648e-14  ...  0.140478   \n",
       "6        0.273205  0.545667 -0.296745 -0.163178  3.398648e-14  ... -0.309888   \n",
       "8        0.251670  0.320053 -0.242486 -0.163178  3.398648e-14  ...  0.067075   \n",
       "...           ...       ...       ...       ...           ...  ...       ...   \n",
       "2675118 -0.822243  0.166855 -0.296745  0.905304  3.879120e-01  ... -0.144609   \n",
       "2675120 -0.591698  0.670025 -0.296745  0.116549  4.157917e-01  ...  1.640388   \n",
       "2675122 -0.326229  1.055277 -0.296745  0.016964  5.271002e-02  ...  1.059105   \n",
       "2675124  0.025713  1.505349 -0.296745  0.265610 -2.630277e-01  ... -0.010583   \n",
       "2675126  0.340786  1.726775 -0.296745  0.926236 -4.489000e-01  ... -0.148565   \n",
       "\n",
       "            RSI-3    MACD-3  MACD_H-3  Variation-4     Vol-4     RSI-4  \\\n",
       "0        0.796397  0.087233  0.089257    -0.514960 -0.295570  2.660454   \n",
       "2       -0.691035 -0.079503 -0.318178    -0.442047 -0.344218 -0.293868   \n",
       "4        0.068701 -0.042420 -0.116987     0.380942  0.367259 -0.266264   \n",
       "6        0.076674  0.063604  0.196784     0.022998 -0.307925  0.058271   \n",
       "8        0.433254  0.213927  0.486277    -0.000092 -0.131674  0.432820   \n",
       "...           ...       ...       ...          ...       ...       ...   \n",
       "2675118 -0.599621 -0.852356  0.044756     0.028691 -0.183870 -0.424827   \n",
       "2675120 -0.715009 -0.946685 -0.202488     0.056217  1.563090 -0.454848   \n",
       "2675122 -0.233153 -0.735235  0.363404     0.541444 -0.123238 -0.097895   \n",
       "2675124  0.128702 -0.449689  0.911287     0.224667 -0.139513  0.126447   \n",
       "2675126  0.836063 -0.136921  1.344475     0.022950 -0.025056  0.340013   \n",
       "\n",
       "           MACD-4  MACD_H-4  Target  \n",
       "0        0.163399  0.363161       1  \n",
       "2       -0.036330 -0.255116       1  \n",
       "4       -0.058034 -0.197810       1  \n",
       "6       -0.026308 -0.051013       0  \n",
       "8        0.133421  0.341924       1  \n",
       "...           ...       ...     ...  \n",
       "2675118 -0.774573  0.312876       1  \n",
       "2675120 -0.886675 -0.054885       1  \n",
       "2675122 -0.822243  0.166855       1  \n",
       "2675124 -0.591698  0.670025       1  \n",
       "2675126 -0.326229  1.055277       0  \n",
       "\n",
       "[1337564 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = predict_data.corr(\"pearson\")\n",
    "#corr[[\"Target\"]].to_clipboard()\n",
    "#corr[[\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mode = \"RAND\"\n",
    "\n",
    "if split_mode == \"RAND\":\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\", \"Unix\", \"Target\"],axis=1), predict_data[\"Target\"], test_size=0.2, random_state=100)\n",
    "elif split_mode == \"STATIC\":\n",
    "    train_data = predict_data[0:int(0.66*len(predict_data))].drop([\"Date\", \"Unix\", \"Target\"],axis=1)\n",
    "    train_labels = predict_data[0:int(0.66*len(predict_data))][\"Target\"]\n",
    "    test_data = predict_data[int(0.66*len(predict_data)):len(predict_data)].drop([\"Date\", \"Unix\", \"Target\"],axis=1)\n",
    "    test_labels = predict_data[int(0.66*len(predict_data)):len(predict_data)][\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = \"MLP\"\n",
    "\n",
    "if algo == \"MLP\":\n",
    "    model = MLPClassifier(hidden_layer_sizes=(200,2000,200),verbose=True)\n",
    "elif algo == \"RF\":\n",
    "    model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "elif algo == \"CAT\":\n",
    "    model = CatBoostClassifier(iterations=100,depth=12)\n",
    "elif algo == \"TREE\":\n",
    "    model = DecisionTreeClassifier(splitter=\"random\")\n",
    "model.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5018050541516246"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53, 72],\n",
       "       [66, 86]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44537815126050423"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5443037974683544"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_loop(predict_data, model_name):\n",
    "    scores = []\n",
    "    TPs = []\n",
    "    TNs = []\n",
    "    for randomize in range(1,20):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\", \"Unix\", \"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=randomize)\n",
    "        if model_name == \"MLP\":\n",
    "            model = MLPClassifier(hidden_layer_sizes=(200,2000,200))\n",
    "        elif model_name == \"CAT\":\n",
    "            model = CatBoostClassifier(iterations=100,depth=12,verbose=False)\n",
    "        elif model_name == \"RF\":\n",
    "            model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "        model.fit(train_data, train_labels)\n",
    "        scores.append(model.score(test_data, test_labels))\n",
    "        conf = confusion_matrix(test_labels,model.predict(test_data))\n",
    "        TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "        TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "        TPs.append(TP)\n",
    "        TNs.append(TN)\n",
    "        print(\"Score : {} || TP : {} || TN : {}\".format(scores[-1],TP,TN))\n",
    "\n",
    "\n",
    "    return scores,TPs,TNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores,TPs,TNs = cross_validation_loop(predict_data,\"CAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen : 0.5067452023560707 || TP moyen : 0.5411620348700146 || TN moyen : 0.4619500842660272\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.51985559566787 || TP : 0.5694444444444444 || TN : 0.46616541353383456\n",
      "Score : 0.49458483754512633 || TP : 0.5194805194805194 || TN : 0.4634146341463415\n",
      "Score : 0.5054151624548736 || TP : 0.5465116279069767 || TN : 0.4380952380952381\n",
      "Score : 0.48375451263537905 || TP : 0.5136986301369864 || TN : 0.45038167938931295\n",
      "Score : 0.4693140794223827 || TP : 0.4722222222222222 || TN : 0.4639175257731959\n",
      "Score : 0.48736462093862815 || TP : 0.525 || TN : 0.4358974358974359\n",
      "Score : 0.51985559566787 || TP : 0.5280898876404494 || TN : 0.5050505050505051\n",
      "Score : 0.49458483754512633 || TP : 0.5611510791366906 || TN : 0.427536231884058\n",
      "Score : 0.49458483754512633 || TP : 0.5384615384615384 || TN : 0.4380165289256198\n",
      "Score : 0.4657039711191336 || TP : 0.4899328859060403 || TN : 0.4375\n",
      "Score : 0.4693140794223827 || TP : 0.5205479452054794 || TN : 0.4122137404580153\n",
      "Score : 0.5306859205776173 || TP : 0.5714285714285714 || TN : 0.46788990825688076\n",
      "Score : 0.4584837545126354 || TP : 0.5 || TN : 0.408\n",
      "Score : 0.5379061371841155 || TP : 0.5757575757575758 || TN : 0.48214285714285715\n",
      "Score : 0.5090252707581228 || TP : 0.5054945054945055 || TN : 0.5157894736842106\n",
      "Score : 0.5342960288808665 || TP : 0.5511363636363636 || TN : 0.504950495049505\n",
      "Score : 0.5487364620938628 || TP : 0.6050955414012739 || TN : 0.475\n",
      "Score : 0.5270758122743683 || TP : 0.567741935483871 || TN : 0.47540983606557374\n",
      "Score : 0.5270758122743683 || TP : 0.5636363636363636 || TN : 0.4732142857142857\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score moyen : 0.5040851225536767 || TP moyen : 0.538149033546309 || TN moyen : 0.4600308310035195\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.51985559566787 || TP : 0.5675675675675675 || TN : 0.46511627906976744\n",
      "Score : 0.48014440433212996 || TP : 0.5068493150684932 || TN : 0.45038167938931295\n",
      "Score : 0.5126353790613718 || TP : 0.56 || TN : 0.4566929133858268\n",
      "Score : 0.5234657039711191 || TP : 0.5496688741721855 || TN : 0.49206349206349204\n",
      "Score : 0.4657039711191336 || TP : 0.46308724832214765 || TN : 0.46875\n",
      "Score : 0.5342960288808665 || TP : 0.5734265734265734 || TN : 0.4925373134328358\n",
      "Score : 0.5270758122743683 || TP : 0.541095890410959 || TN : 0.5114503816793893\n",
      "Score : 0.5054151624548736 || TP : 0.5657894736842105 || TN : 0.432\n",
      "Score : 0.48014440433212996 || TP : 0.5266666666666666 || TN : 0.4251968503937008\n",
      "Score : 0.5090252707581228 || TP : 0.5302013422818792 || TN : 0.484375\n",
      "Score : 0.5126353790613718 || TP : 0.56 || TN : 0.4566929133858268\n",
      "Score : 0.5451263537906137 || TP : 0.5933333333333334 || TN : 0.4881889763779528\n",
      "Score : 0.4729241877256318 || TP : 0.5131578947368421 || TN : 0.424\n",
      "Score : 0.5342960288808665 || TP : 0.5845070422535211 || TN : 0.48148148148148145\n",
      "Score : 0.5018050541516246 || TP : 0.5 || TN : 0.5037593984962406\n",
      "Score : 0.51985559566787 || TP : 0.5460526315789473 || TN : 0.488\n",
      "Score : 0.5054151624548736 || TP : 0.5695364238410596 || TN : 0.42857142857142855\n",
      "Score : 0.48014440433212996 || TP : 0.5256410256410257 || TN : 0.4214876033057851\n",
      "Score : 0.51985559566787 || TP : 0.5664335664335665 || TN : 0.4701492537313433\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP score moyen : 0.5078852365570967 || TP moyen : 0.5443692036536304 || TN moyen : 0.4653102613033886\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exï¿½cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (len(predict_data.columns)-2,)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=shape),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562, 48) (277, 48)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 142ms/step - loss: 0.7538 - accuracy: 0.5320 - precision: 0.5391 - recall: 0.8087 - val_loss: 0.6873 - val_accuracy: 0.5487 - val_precision: 0.5487 - val_recall: 1.0000\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 0.6805 - accuracy: 0.5302 - precision: 0.5304 - recall: 0.9966 - val_loss: 0.6878 - val_accuracy: 0.5668 - val_precision: 0.5769 - val_recall: 0.7895\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 0.6691 - accuracy: 0.5765 - precision: 0.5743 - recall: 0.7785 - val_loss: 0.6927 - val_accuracy: 0.5307 - val_precision: 0.5775 - val_recall: 0.5395\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.6651 - accuracy: 0.6139 - precision: 0.6421 - recall: 0.6141 - val_loss: 0.7008 - val_accuracy: 0.5523 - val_precision: 0.5854 - val_recall: 0.6316\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.6455 - accuracy: 0.6423 - precision: 0.6667 - recall: 0.6510 - val_loss: 0.7416 - val_accuracy: 0.5126 - val_precision: 0.5669 - val_recall: 0.4737\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 0.6043 - accuracy: 0.6708 - precision: 0.7116 - recall: 0.6376 - val_loss: 0.7345 - val_accuracy: 0.5054 - val_precision: 0.5789 - val_recall: 0.3618\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.5761 - accuracy: 0.6851 - precision: 0.7336 - recall: 0.6376 - val_loss: 0.7907 - val_accuracy: 0.4838 - val_precision: 0.5344 - val_recall: 0.4605\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.5255 - accuracy: 0.7367 - precision: 0.7757 - recall: 0.7081 - val_loss: 0.8596 - val_accuracy: 0.4621 - val_precision: 0.5190 - val_recall: 0.2697\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.4910 - accuracy: 0.7544 - precision: 0.8030 - recall: 0.7114 - val_loss: 0.9029 - val_accuracy: 0.4838 - val_precision: 0.5287 - val_recall: 0.5461\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.4297 - accuracy: 0.7989 - precision: 0.8339 - recall: 0.7752 - val_loss: 1.0199 - val_accuracy: 0.4910 - val_precision: 0.5337 - val_recall: 0.5724\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.3645 - accuracy: 0.8167 - precision: 0.8545 - recall: 0.7886 - val_loss: 1.4128 - val_accuracy: 0.5126 - val_precision: 0.5399 - val_recall: 0.7566\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.2917 - accuracy: 0.8719 - precision: 0.8844 - recall: 0.8725 - val_loss: 1.2036 - val_accuracy: 0.5090 - val_precision: 0.5513 - val_recall: 0.5658\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 0.2051 - accuracy: 0.9128 - precision: 0.9338 - recall: 0.8993 - val_loss: 1.6257 - val_accuracy: 0.4765 - val_precision: 0.5200 - val_recall: 0.5987\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.1910 - accuracy: 0.9181 - precision: 0.9145 - recall: 0.9329 - val_loss: 2.0143 - val_accuracy: 0.4765 - val_precision: 0.5207 - val_recall: 0.5789\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.1838 - accuracy: 0.9164 - precision: 0.9254 - recall: 0.9161 - val_loss: 1.5950 - val_accuracy: 0.4838 - val_precision: 0.5319 - val_recall: 0.4934\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.1378 - accuracy: 0.9466 - precision: 0.9497 - recall: 0.9497 - val_loss: 1.7479 - val_accuracy: 0.5379 - val_precision: 0.6017 - val_recall: 0.4671\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.1407 - accuracy: 0.9520 - precision: 0.9532 - recall: 0.9564 - val_loss: 2.1295 - val_accuracy: 0.4874 - val_precision: 0.5325 - val_recall: 0.5395\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 0.1156 - accuracy: 0.9484 - precision: 0.9559 - recall: 0.9463 - val_loss: 2.1885 - val_accuracy: 0.4946 - val_precision: 0.5429 - val_recall: 0.5000\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 0.1015 - accuracy: 0.9591 - precision: 0.9568 - recall: 0.9664 - val_loss: 2.3965 - val_accuracy: 0.4765 - val_precision: 0.5248 - val_recall: 0.4868\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 0.1526 - accuracy: 0.9448 - precision: 0.9495 - recall: 0.9463 - val_loss: 1.8993 - val_accuracy: 0.4982 - val_precision: 0.5430 - val_recall: 0.5395oss: 0.1529 - accuracy: 0.9554 - precision: 0.9496 - rec\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.1521 - accuracy: 0.9466 - precision: 0.9653 - recall: 0.9329 - val_loss: 1.9083 - val_accuracy: 0.5199 - val_precision: 0.5583 - val_recall: 0.5987\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 2s 141ms/step - loss: 0.1349 - accuracy: 0.9502 - precision: 0.9470 - recall: 0.9597 - val_loss: 2.0300 - val_accuracy: 0.5126 - val_precision: 0.5548 - val_recall: 0.5658\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.0826 - accuracy: 0.9751 - precision: 0.9797 - recall: 0.9732 - val_loss: 2.0398 - val_accuracy: 0.5054 - val_precision: 0.5532 - val_recall: 0.5132\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 123ms/step - loss: 0.0507 - accuracy: 0.9840 - precision: 0.9833 - recall: 0.9866 - val_loss: 2.4049 - val_accuracy: 0.4838 - val_precision: 0.5328 - val_recall: 0.4803\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.0375 - accuracy: 0.9840 - precision: 0.9865 - recall: 0.9832 - val_loss: 2.3831 - val_accuracy: 0.5090 - val_precision: 0.5678 - val_recall: 0.4408\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.0234 - accuracy: 0.9929 - precision: 0.9900 - recall: 0.9966 - val_loss: 2.5314 - val_accuracy: 0.5054 - val_precision: 0.5547 - val_recall: 0.5000\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0126 - accuracy: 0.9964 - precision: 0.9966 - recall: 0.9966 - val_loss: 2.7888 - val_accuracy: 0.4910 - val_precision: 0.5314 - val_recall: 0.6118\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.0047 - accuracy: 0.9982 - precision: 1.0000 - recall: 0.9966 - val_loss: 2.9194 - val_accuracy: 0.4765 - val_precision: 0.5223 - val_recall: 0.5395\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.0061 - accuracy: 0.9982 - precision: 0.9967 - recall: 1.0000 - val_loss: 2.9351 - val_accuracy: 0.4946 - val_precision: 0.5423 - val_recall: 0.5066\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0066 - accuracy: 0.9964 - precision: 0.9966 - recall: 0.9966 - val_loss: 3.0533 - val_accuracy: 0.5090 - val_precision: 0.5526 - val_recall: 0.5526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2631d130d90>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=30, validation_data=(test_data,test_labels),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 3.1906 - accuracy: 0.4414 - precision: 0.5116 - recall: 0.3492 - 28ms/epoch - 7ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7593e2cc95d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTest accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(probability_model.predict(test_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 74],\n",
       "       [62, 90]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45132743362831856"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5487804878048781"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
