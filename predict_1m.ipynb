{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"minute_data/BTC-USD_1M_SIGNALS.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>-DM</th>\n",
       "      <th>+DM</th>\n",
       "      <th>ADX14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764620</td>\n",
       "      <td>2017-12-31 23:57:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13908.73</td>\n",
       "      <td>13913.26</td>\n",
       "      <td>13874.99</td>\n",
       "      <td>13913.26</td>\n",
       "      <td>-0.295570</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>3.246953</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.363161</td>\n",
       "      <td>0.229565</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764560</td>\n",
       "      <td>2017-12-31 23:56:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13827.00</td>\n",
       "      <td>13908.69</td>\n",
       "      <td>13827.00</td>\n",
       "      <td>13859.58</td>\n",
       "      <td>-0.303185</td>\n",
       "      <td>-0.684081</td>\n",
       "      <td>0.974031</td>\n",
       "      <td>0.087233</td>\n",
       "      <td>0.089257</td>\n",
       "      <td>2.307135</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514764500</td>\n",
       "      <td>2017-12-31 23:55:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>13825.05</td>\n",
       "      <td>-0.344218</td>\n",
       "      <td>-0.442047</td>\n",
       "      <td>-0.355376</td>\n",
       "      <td>-0.036330</td>\n",
       "      <td>-0.255116</td>\n",
       "      <td>-0.190940</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1514764440</td>\n",
       "      <td>2017-12-31 23:54:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13884.14</td>\n",
       "      <td>13884.14</td>\n",
       "      <td>13823.88</td>\n",
       "      <td>13854.28</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.373551</td>\n",
       "      <td>-0.839658</td>\n",
       "      <td>-0.079503</td>\n",
       "      <td>-0.318178</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>1.710867</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1514764380</td>\n",
       "      <td>2017-12-31 23:53:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>13854.52</td>\n",
       "      <td>13898.70</td>\n",
       "      <td>13840.85</td>\n",
       "      <td>13884.15</td>\n",
       "      <td>0.367259</td>\n",
       "      <td>0.380942</td>\n",
       "      <td>-0.321717</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674991</th>\n",
       "      <td>1609459500</td>\n",
       "      <td>2021-01-01 00:05:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29021.86</td>\n",
       "      <td>29023.38</td>\n",
       "      <td>28982.33</td>\n",
       "      <td>28999.50</td>\n",
       "      <td>-0.196942</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.806634</td>\n",
       "      <td>0.156727</td>\n",
       "      <td>1.550490</td>\n",
       "      <td>0.483496</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-3.812808e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674992</th>\n",
       "      <td>1609459440</td>\n",
       "      <td>2021-01-01 00:04:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29048.13</td>\n",
       "      <td>29057.73</td>\n",
       "      <td>29035.61</td>\n",
       "      <td>29045.19</td>\n",
       "      <td>-0.141744</td>\n",
       "      <td>0.278150</td>\n",
       "      <td>1.300388</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>1.726775</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.926236</td>\n",
       "      <td>-4.520608e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674993</th>\n",
       "      <td>1609459380</td>\n",
       "      <td>2021-01-01 00:03:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29037.68</td>\n",
       "      <td>29069.39</td>\n",
       "      <td>29019.00</td>\n",
       "      <td>29048.13</td>\n",
       "      <td>-0.035411</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>1.437312</td>\n",
       "      <td>0.486452</td>\n",
       "      <td>1.766349</td>\n",
       "      <td>0.604494</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-5.749948e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674994</th>\n",
       "      <td>1609459320</td>\n",
       "      <td>2021-01-01 00:02:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29069.80</td>\n",
       "      <td>29073.02</td>\n",
       "      <td>29028.14</td>\n",
       "      <td>29035.89</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>-0.075473</td>\n",
       "      <td>1.262523</td>\n",
       "      <td>0.572733</td>\n",
       "      <td>1.641080</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>-0.048052</td>\n",
       "      <td>-6.576199e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674995</th>\n",
       "      <td>1609459260</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>29007.31</td>\n",
       "      <td>29086.90</td>\n",
       "      <td>29007.31</td>\n",
       "      <td>29083.47</td>\n",
       "      <td>1.737225</td>\n",
       "      <td>0.289327</td>\n",
       "      <td>2.389313</td>\n",
       "      <td>0.720446</td>\n",
       "      <td>1.703201</td>\n",
       "      <td>0.833466</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-7.296304e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2674996 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unix                 Date  ...       +DM         ADX14\n",
       "0        1514764620  2017-12-31 23:57:00  ... -0.163178 -4.267351e-16\n",
       "1        1514764560  2017-12-31 23:56:00  ... -0.163178 -4.267351e-16\n",
       "2        1514764500  2017-12-31 23:55:00  ... -0.163178 -4.267351e-16\n",
       "3        1514764440  2017-12-31 23:54:00  ...  1.710867 -4.267351e-16\n",
       "4        1514764380  2017-12-31 23:53:00  ...  0.298594 -4.267351e-16\n",
       "...             ...                  ...  ...       ...           ...\n",
       "2674991  1609459500  2021-01-01 00:05:00  ... -0.163178 -3.812808e-01\n",
       "2674992  1609459440  2021-01-01 00:04:00  ...  0.926236 -4.520608e-01\n",
       "2674993  1609459380  2021-01-01 00:03:00  ... -0.163178 -5.749948e-01\n",
       "2674994  1609459320  2021-01-01 00:02:00  ... -0.048052 -6.576199e-01\n",
       "2674995  1609459260  2021-01-01 00:01:00  ... -0.163178 -7.296304e-01\n",
       "\n",
       "[2674996 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = data.copy().drop([\"Open\",\"Close\",\"High\",\"Low\", \"Symbol\"],axis=1)\n",
    "max_days = 5\n",
    "target_range = 2\n",
    "for i in range(1,max_days):#2jours\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\"]].shift(i)\n",
    "    #predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i),\"CONF-{}\".format(i),\"TRANS-{}\".format(i),\"REV-{}\".format(i),\"FnG-{}\".format(i), \"ADX-{}\".format(i), \"+DM-{}\".format(i), \"-DM-{}\".format(i)]] = data[[\"Variation\",\"Volume\",\"RSI\",\"MACD\",\"MACD_H\",\"Confirmation Time\",\"Transactions\",\"Miners Revenue\",\"FnG\",\"ADX14\",\"+DM\",\"-DM\"]].shift(i)\n",
    "    predict_data[[\"Variation-{}\".format(i),\"Vol-{}\".format(i),\"RSI-{}\".format(i),\"MACD-{}\".format(i),\"MACD_H-{}\".format(i)]] = data[[\"Variation\",\"Volume USD\",\"RSI\",\"MACD\",\"MACD_H\"]].shift(i)\n",
    "#predict_data[\"Target\"] = (data[\"Variation\"].shift(-1) >= 0)\n",
    "predict_data[\"Target\"] = (data[\"Close\"].shift(-target_range) - data[\"Close\"] >= 0)\n",
    "predict_data[\"Target\"] = np.where(predict_data[\"Target\"] == True, 1, 0)\n",
    "predict_data.dropna(inplace=True)\n",
    "predict_data.reset_index(inplace=True,drop=True)\n",
    "predict_data = predict_data[0:len(predict_data)-target_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = predict_data[[i % int(max_days) == 0 for i in range(len(predict_data))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Variation</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_H</th>\n",
       "      <th>-DM</th>\n",
       "      <th>+DM</th>\n",
       "      <th>ADX14</th>\n",
       "      <th>Variation-1</th>\n",
       "      <th>Vol-1</th>\n",
       "      <th>RSI-1</th>\n",
       "      <th>MACD-1</th>\n",
       "      <th>MACD_H-1</th>\n",
       "      <th>Variation-2</th>\n",
       "      <th>Vol-2</th>\n",
       "      <th>RSI-2</th>\n",
       "      <th>MACD-2</th>\n",
       "      <th>MACD_H-2</th>\n",
       "      <th>Variation-3</th>\n",
       "      <th>Vol-3</th>\n",
       "      <th>RSI-3</th>\n",
       "      <th>MACD-3</th>\n",
       "      <th>MACD_H-3</th>\n",
       "      <th>Variation-4</th>\n",
       "      <th>Vol-4</th>\n",
       "      <th>RSI-4</th>\n",
       "      <th>MACD-4</th>\n",
       "      <th>MACD_H-4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764380</td>\n",
       "      <td>2017-12-31 23:53:00</td>\n",
       "      <td>0.367259</td>\n",
       "      <td>0.380942</td>\n",
       "      <td>-0.321717</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "      <td>0.373551</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>-0.839658</td>\n",
       "      <td>-0.079503</td>\n",
       "      <td>-0.318178</td>\n",
       "      <td>-0.442047</td>\n",
       "      <td>-0.344218</td>\n",
       "      <td>-0.355376</td>\n",
       "      <td>-0.036330</td>\n",
       "      <td>-0.255116</td>\n",
       "      <td>-0.684081</td>\n",
       "      <td>-0.303185</td>\n",
       "      <td>0.974031</td>\n",
       "      <td>0.087233</td>\n",
       "      <td>0.089257</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>-0.295570</td>\n",
       "      <td>3.246953</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.363161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1514764080</td>\n",
       "      <td>2017-12-31 23:48:00</td>\n",
       "      <td>0.067075</td>\n",
       "      <td>0.189996</td>\n",
       "      <td>0.531235</td>\n",
       "      <td>0.213927</td>\n",
       "      <td>0.486277</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.303351</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.131674</td>\n",
       "      <td>0.530705</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.538370</td>\n",
       "      <td>-0.309888</td>\n",
       "      <td>0.096442</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>0.022998</td>\n",
       "      <td>-0.307925</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.051013</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>0.140478</td>\n",
       "      <td>0.086720</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.116987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1514763780</td>\n",
       "      <td>2017-12-31 23:43:00</td>\n",
       "      <td>0.079739</td>\n",
       "      <td>0.496962</td>\n",
       "      <td>0.176112</td>\n",
       "      <td>0.231868</td>\n",
       "      <td>0.178763</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>-0.155567</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "      <td>-0.496770</td>\n",
       "      <td>0.179185</td>\n",
       "      <td>-0.494481</td>\n",
       "      <td>0.201988</td>\n",
       "      <td>0.124756</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>-0.322627</td>\n",
       "      <td>0.421305</td>\n",
       "      <td>0.251670</td>\n",
       "      <td>0.320053</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.227993</td>\n",
       "      <td>0.648752</td>\n",
       "      <td>0.220731</td>\n",
       "      <td>0.297869</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>-0.348619</td>\n",
       "      <td>0.657538</td>\n",
       "      <td>0.273205</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1514763480</td>\n",
       "      <td>2017-12-31 23:38:00</td>\n",
       "      <td>-0.061720</td>\n",
       "      <td>0.535950</td>\n",
       "      <td>1.059072</td>\n",
       "      <td>0.533913</td>\n",
       "      <td>0.569550</td>\n",
       "      <td>-0.266360</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-4.267351e-16</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.138692</td>\n",
       "      <td>0.761273</td>\n",
       "      <td>0.452176</td>\n",
       "      <td>0.441947</td>\n",
       "      <td>-0.408320</td>\n",
       "      <td>-0.211435</td>\n",
       "      <td>0.972935</td>\n",
       "      <td>0.439608</td>\n",
       "      <td>0.510920</td>\n",
       "      <td>0.378815</td>\n",
       "      <td>-0.253362</td>\n",
       "      <td>1.541763</td>\n",
       "      <td>0.416904</td>\n",
       "      <td>0.563653</td>\n",
       "      <td>0.378866</td>\n",
       "      <td>-0.041567</td>\n",
       "      <td>0.939382</td>\n",
       "      <td>0.307023</td>\n",
       "      <td>0.341611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1514763180</td>\n",
       "      <td>2017-12-31 23:33:00</td>\n",
       "      <td>-0.327387</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.480053</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>1.105845</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>-6.727399e-01</td>\n",
       "      <td>-0.395197</td>\n",
       "      <td>-0.260645</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>0.522682</td>\n",
       "      <td>0.166829</td>\n",
       "      <td>0.309211</td>\n",
       "      <td>0.714781</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.569268</td>\n",
       "      <td>0.362417</td>\n",
       "      <td>-0.302037</td>\n",
       "      <td>-0.223150</td>\n",
       "      <td>0.363244</td>\n",
       "      <td>0.548028</td>\n",
       "      <td>0.382862</td>\n",
       "      <td>-0.154288</td>\n",
       "      <td>-0.308199</td>\n",
       "      <td>0.911942</td>\n",
       "      <td>0.569766</td>\n",
       "      <td>0.550384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674965</th>\n",
       "      <td>1609460820</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>0.590014</td>\n",
       "      <td>0.087136</td>\n",
       "      <td>-0.845958</td>\n",
       "      <td>-0.955965</td>\n",
       "      <td>-0.036870</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.175856</td>\n",
       "      <td>6.274754e-01</td>\n",
       "      <td>-0.067007</td>\n",
       "      <td>1.235547</td>\n",
       "      <td>-1.119984</td>\n",
       "      <td>-0.958632</td>\n",
       "      <td>-0.054895</td>\n",
       "      <td>-0.240210</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>-1.079694</td>\n",
       "      <td>-0.914725</td>\n",
       "      <td>0.076414</td>\n",
       "      <td>0.114157</td>\n",
       "      <td>1.370075</td>\n",
       "      <td>-0.904186</td>\n",
       "      <td>-0.870496</td>\n",
       "      <td>0.241613</td>\n",
       "      <td>-0.103320</td>\n",
       "      <td>2.129406</td>\n",
       "      <td>-0.567747</td>\n",
       "      <td>-0.892352</td>\n",
       "      <td>0.229824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674970</th>\n",
       "      <td>1609460520</td>\n",
       "      <td>2021-01-01 00:22:00</td>\n",
       "      <td>-0.105216</td>\n",
       "      <td>-0.184985</td>\n",
       "      <td>-1.236472</td>\n",
       "      <td>-0.858640</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>0.416216</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>5.892400e-01</td>\n",
       "      <td>0.073330</td>\n",
       "      <td>-0.024904</td>\n",
       "      <td>-0.731635</td>\n",
       "      <td>-0.841248</td>\n",
       "      <td>0.206535</td>\n",
       "      <td>-0.154789</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>-0.725001</td>\n",
       "      <td>-0.876723</td>\n",
       "      <td>0.140989</td>\n",
       "      <td>0.073664</td>\n",
       "      <td>-0.164294</td>\n",
       "      <td>-0.509659</td>\n",
       "      <td>-0.881114</td>\n",
       "      <td>0.161733</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>2.994560</td>\n",
       "      <td>-0.917234</td>\n",
       "      <td>-0.932375</td>\n",
       "      <td>0.032842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674975</th>\n",
       "      <td>1609460220</td>\n",
       "      <td>2021-01-01 00:17:00</td>\n",
       "      <td>-0.287596</td>\n",
       "      <td>-0.061275</td>\n",
       "      <td>-0.363714</td>\n",
       "      <td>-0.821848</td>\n",
       "      <td>0.234938</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>-0.163178</td>\n",
       "      <td>4.120796e-01</td>\n",
       "      <td>-0.111944</td>\n",
       "      <td>0.440705</td>\n",
       "      <td>-0.418507</td>\n",
       "      <td>-0.859043</td>\n",
       "      <td>0.170810</td>\n",
       "      <td>0.543953</td>\n",
       "      <td>-0.071406</td>\n",
       "      <td>-0.484481</td>\n",
       "      <td>-0.916955</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>-0.151104</td>\n",
       "      <td>-0.082928</td>\n",
       "      <td>-1.319534</td>\n",
       "      <td>-1.019712</td>\n",
       "      <td>-0.311650</td>\n",
       "      <td>-0.227717</td>\n",
       "      <td>0.736099</td>\n",
       "      <td>-1.454281</td>\n",
       "      <td>-0.929892</td>\n",
       "      <td>-0.092872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674980</th>\n",
       "      <td>1609459920</td>\n",
       "      <td>2021-01-01 00:12:00</td>\n",
       "      <td>-0.123238</td>\n",
       "      <td>0.541444</td>\n",
       "      <td>-0.116417</td>\n",
       "      <td>-0.822243</td>\n",
       "      <td>0.166855</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.905304</td>\n",
       "      <td>3.885019e-01</td>\n",
       "      <td>-0.146590</td>\n",
       "      <td>1.640388</td>\n",
       "      <td>-0.868890</td>\n",
       "      <td>-0.946685</td>\n",
       "      <td>-0.202488</td>\n",
       "      <td>0.056217</td>\n",
       "      <td>1.563090</td>\n",
       "      <td>-0.551666</td>\n",
       "      <td>-0.886675</td>\n",
       "      <td>-0.054885</td>\n",
       "      <td>-0.416947</td>\n",
       "      <td>-0.144609</td>\n",
       "      <td>-0.728193</td>\n",
       "      <td>-0.852356</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>-0.183870</td>\n",
       "      <td>-0.515060</td>\n",
       "      <td>-0.774573</td>\n",
       "      <td>0.312876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674985</th>\n",
       "      <td>1609459620</td>\n",
       "      <td>2021-01-01 00:07:00</td>\n",
       "      <td>-0.148565</td>\n",
       "      <td>0.297738</td>\n",
       "      <td>1.022397</td>\n",
       "      <td>-0.136921</td>\n",
       "      <td>1.344475</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.427674</td>\n",
       "      <td>-1.342856e-01</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>-0.326229</td>\n",
       "      <td>1.055277</td>\n",
       "      <td>0.075856</td>\n",
       "      <td>-0.010583</td>\n",
       "      <td>0.159882</td>\n",
       "      <td>-0.449689</td>\n",
       "      <td>0.911287</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>-0.139513</td>\n",
       "      <td>0.157132</td>\n",
       "      <td>-0.591698</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>-0.067646</td>\n",
       "      <td>1.059105</td>\n",
       "      <td>-0.281343</td>\n",
       "      <td>-0.735235</td>\n",
       "      <td>0.363404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534998 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unix                 Date  ...  MACD_H-4  Target\n",
       "0        1514764380  2017-12-31 23:53:00  ...  0.363161       1\n",
       "5        1514764080  2017-12-31 23:48:00  ... -0.116987       0\n",
       "10       1514763780  2017-12-31 23:43:00  ...  0.545667       1\n",
       "15       1514763480  2017-12-31 23:38:00  ...  0.341611       0\n",
       "20       1514763180  2017-12-31 23:33:00  ...  0.550384       0\n",
       "...             ...                  ...  ...       ...     ...\n",
       "2674965  1609460820  2021-01-01 00:27:00  ...  0.229824       1\n",
       "2674970  1609460520  2021-01-01 00:22:00  ...  0.032842       0\n",
       "2674975  1609460220  2021-01-01 00:17:00  ... -0.092872       0\n",
       "2674980  1609459920  2021-01-01 00:12:00  ...  0.312876       1\n",
       "2674985  1609459620  2021-01-01 00:07:00  ...  0.363404       1\n",
       "\n",
       "[534998 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = predict_data.corr(\"pearson\")\n",
    "#corr[[\"Target\"]].to_clipboard()\n",
    "#corr[[\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mode = \"RAND\"\n",
    "\n",
    "if split_mode == \"RAND\":\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\", \"Unix\", \"Target\"],axis=1), predict_data[\"Target\"], test_size=0.2, random_state=100)\n",
    "elif split_mode == \"STATIC\":\n",
    "    train_data = predict_data[0:int(0.66*len(predict_data))].drop([\"Date\", \"Unix\", \"Target\"],axis=1)\n",
    "    train_labels = predict_data[0:int(0.66*len(predict_data))][\"Target\"]\n",
    "    test_data = predict_data[int(0.66*len(predict_data)):len(predict_data)].drop([\"Date\", \"Unix\", \"Target\"],axis=1)\n",
    "    test_labels = predict_data[int(0.66*len(predict_data)):len(predict_data)][\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65398021\n",
      "Iteration 2, loss = 0.64336664\n",
      "Iteration 3, loss = 0.63996147\n",
      "Iteration 4, loss = 0.63833888\n",
      "Iteration 5, loss = 0.63697008\n",
      "Iteration 6, loss = 0.63595846\n",
      "Iteration 7, loss = 0.63490123\n",
      "Iteration 8, loss = 0.63386533\n",
      "Iteration 9, loss = 0.63308808\n",
      "Iteration 10, loss = 0.63230100\n",
      "Iteration 11, loss = 0.63149277\n",
      "Iteration 12, loss = 0.63073962\n",
      "Iteration 13, loss = 0.62990224\n",
      "Iteration 14, loss = 0.62882980\n",
      "Iteration 15, loss = 0.62831250\n",
      "Iteration 16, loss = 0.62773880\n",
      "Iteration 17, loss = 0.62650033\n",
      "Iteration 18, loss = 0.62577357\n",
      "Iteration 19, loss = 0.62499218\n",
      "Iteration 20, loss = 0.62419966\n",
      "Iteration 21, loss = 0.62347343\n",
      "Iteration 22, loss = 0.62242316\n",
      "Iteration 23, loss = 0.62162843\n",
      "Iteration 24, loss = 0.62097936\n",
      "Iteration 25, loss = 0.61968942\n",
      "Iteration 26, loss = 0.61909913\n",
      "Iteration 27, loss = 0.61817302\n",
      "Iteration 28, loss = 0.61718370\n",
      "Iteration 29, loss = 0.61618977\n",
      "Iteration 30, loss = 0.61551841\n",
      "Iteration 31, loss = 0.61454742\n",
      "Iteration 32, loss = 0.61350362\n",
      "Iteration 33, loss = 0.61299900\n",
      "Iteration 34, loss = 0.61190042\n",
      "Iteration 35, loss = 0.61102546\n",
      "Iteration 36, loss = 0.61010194\n",
      "Iteration 37, loss = 0.60929205\n",
      "Iteration 38, loss = 0.60868882\n",
      "Iteration 39, loss = 0.60759122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 200, 100), verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = \"MLP\"\n",
    "\n",
    "if algo == \"MLP\":\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,200,100),verbose=True)\n",
    "elif algo == \"RF\":\n",
    "    model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "elif algo == \"CAT\":\n",
    "    model = CatBoostClassifier(iterations=100,depth=12)\n",
    "elif algo == \"TREE\":\n",
    "    model = DecisionTreeClassifier(splitter=\"random\")\n",
    "model.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5018050541516246"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53, 72],\n",
       "       [66, 86]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44537815126050423"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5443037974683544"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_loop(predict_data, model_name):\n",
    "    scores = []\n",
    "    TPs = []\n",
    "    TNs = []\n",
    "    for randomize in range(1,20):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(predict_data.drop([\"Date\", \"Unix\", \"Target\"],axis=1), predict_data[\"Target\"], test_size=0.33, random_state=randomize)\n",
    "        if model_name == \"MLP\":\n",
    "            model = MLPClassifier(hidden_layer_sizes=(200,2000,200))\n",
    "        elif model_name == \"CAT\":\n",
    "            model = CatBoostClassifier(iterations=100,depth=12,verbose=False)\n",
    "        elif model_name == \"RF\":\n",
    "            model = RandomForestClassifier(n_estimators=100,verbose=False)\n",
    "        model.fit(train_data, train_labels)\n",
    "        scores.append(model.score(test_data, test_labels))\n",
    "        conf = confusion_matrix(test_labels,model.predict(test_data))\n",
    "        TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "        TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "        TPs.append(TP)\n",
    "        TNs.append(TN)\n",
    "        print(\"Score : {} || TP : {} || TN : {}\".format(scores[-1],TP,TN))\n",
    "\n",
    "\n",
    "    return scores,TPs,TNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores,TPs,TNs = cross_validation_loop(predict_data,\"CAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen : 0.5067452023560707 || TP moyen : 0.5411620348700146 || TN moyen : 0.4619500842660272\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.51985559566787 || TP : 0.5694444444444444 || TN : 0.46616541353383456\n",
      "Score : 0.49458483754512633 || TP : 0.5194805194805194 || TN : 0.4634146341463415\n",
      "Score : 0.5054151624548736 || TP : 0.5465116279069767 || TN : 0.4380952380952381\n",
      "Score : 0.48375451263537905 || TP : 0.5136986301369864 || TN : 0.45038167938931295\n",
      "Score : 0.4693140794223827 || TP : 0.4722222222222222 || TN : 0.4639175257731959\n",
      "Score : 0.48736462093862815 || TP : 0.525 || TN : 0.4358974358974359\n",
      "Score : 0.51985559566787 || TP : 0.5280898876404494 || TN : 0.5050505050505051\n",
      "Score : 0.49458483754512633 || TP : 0.5611510791366906 || TN : 0.427536231884058\n",
      "Score : 0.49458483754512633 || TP : 0.5384615384615384 || TN : 0.4380165289256198\n",
      "Score : 0.4657039711191336 || TP : 0.4899328859060403 || TN : 0.4375\n",
      "Score : 0.4693140794223827 || TP : 0.5205479452054794 || TN : 0.4122137404580153\n",
      "Score : 0.5306859205776173 || TP : 0.5714285714285714 || TN : 0.46788990825688076\n",
      "Score : 0.4584837545126354 || TP : 0.5 || TN : 0.408\n",
      "Score : 0.5379061371841155 || TP : 0.5757575757575758 || TN : 0.48214285714285715\n",
      "Score : 0.5090252707581228 || TP : 0.5054945054945055 || TN : 0.5157894736842106\n",
      "Score : 0.5342960288808665 || TP : 0.5511363636363636 || TN : 0.504950495049505\n",
      "Score : 0.5487364620938628 || TP : 0.6050955414012739 || TN : 0.475\n",
      "Score : 0.5270758122743683 || TP : 0.567741935483871 || TN : 0.47540983606557374\n",
      "Score : 0.5270758122743683 || TP : 0.5636363636363636 || TN : 0.4732142857142857\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score moyen : 0.5040851225536767 || TP moyen : 0.538149033546309 || TN moyen : 0.4600308310035195\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.51985559566787 || TP : 0.5675675675675675 || TN : 0.46511627906976744\n",
      "Score : 0.48014440433212996 || TP : 0.5068493150684932 || TN : 0.45038167938931295\n",
      "Score : 0.5126353790613718 || TP : 0.56 || TN : 0.4566929133858268\n",
      "Score : 0.5234657039711191 || TP : 0.5496688741721855 || TN : 0.49206349206349204\n",
      "Score : 0.4657039711191336 || TP : 0.46308724832214765 || TN : 0.46875\n",
      "Score : 0.5342960288808665 || TP : 0.5734265734265734 || TN : 0.4925373134328358\n",
      "Score : 0.5270758122743683 || TP : 0.541095890410959 || TN : 0.5114503816793893\n",
      "Score : 0.5054151624548736 || TP : 0.5657894736842105 || TN : 0.432\n",
      "Score : 0.48014440433212996 || TP : 0.5266666666666666 || TN : 0.4251968503937008\n",
      "Score : 0.5090252707581228 || TP : 0.5302013422818792 || TN : 0.484375\n",
      "Score : 0.5126353790613718 || TP : 0.56 || TN : 0.4566929133858268\n",
      "Score : 0.5451263537906137 || TP : 0.5933333333333334 || TN : 0.4881889763779528\n",
      "Score : 0.4729241877256318 || TP : 0.5131578947368421 || TN : 0.424\n",
      "Score : 0.5342960288808665 || TP : 0.5845070422535211 || TN : 0.48148148148148145\n",
      "Score : 0.5018050541516246 || TP : 0.5 || TN : 0.5037593984962406\n",
      "Score : 0.51985559566787 || TP : 0.5460526315789473 || TN : 0.488\n",
      "Score : 0.5054151624548736 || TP : 0.5695364238410596 || TN : 0.42857142857142855\n",
      "Score : 0.48014440433212996 || TP : 0.5256410256410257 || TN : 0.4214876033057851\n",
      "Score : 0.51985559566787 || TP : 0.5664335664335665 || TN : 0.4701492537313433\n"
     ]
    }
   ],
   "source": [
    "scores,TPs,TNs = cross_validation_loop(predict_data,\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP score moyen : 0.5078852365570967 || TP moyen : 0.5443692036536304 || TN moyen : 0.4653102613033886\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP score moyen : {} || TP moyen : {} || TN moyen : {}\".format(mean(scores),mean(TPs),mean(TNs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (len(predict_data.columns)-3,)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=shape),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427998, 28) (107000, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13375/13375 [==============================] - 456s 34ms/step - loss: 0.6532 - accuracy: 0.6126 - precision: 0.6121 - recall: 0.6741 - val_loss: 0.6450 - val_accuracy: 0.6218 - val_precision: 0.6481 - val_recall: 0.5781\n",
      "Epoch 2/30\n",
      "13375/13375 [==============================] - 459s 34ms/step - loss: 0.6436 - accuracy: 0.6249 - precision: 0.6243 - recall: 0.6806 - val_loss: 0.6397 - val_accuracy: 0.6297 - val_precision: 0.6324 - val_recall: 0.6680\n",
      "Epoch 3/30\n",
      "13375/13375 [==============================] - 450s 34ms/step - loss: 0.6408 - accuracy: 0.6279 - precision: 0.6284 - recall: 0.6773 - val_loss: 0.6426 - val_accuracy: 0.6301 - val_precision: 0.6414 - val_recall: 0.6363\n",
      "Epoch 4/30\n",
      "13375/13375 [==============================] - 504s 38ms/step - loss: 0.6387 - accuracy: 0.6302 - precision: 0.6309 - recall: 0.6776 - val_loss: 0.6373 - val_accuracy: 0.6308 - val_precision: 0.6322 - val_recall: 0.6737\n",
      "Epoch 5/30\n",
      "13375/13375 [==============================] - 477s 36ms/step - loss: 0.6376 - accuracy: 0.6316 - precision: 0.6336 - recall: 0.6733 - val_loss: 0.6426 - val_accuracy: 0.6306 - val_precision: 0.6405 - val_recall: 0.6415\n",
      "Epoch 6/30\n",
      "13375/13375 [==============================] - 490s 37ms/step - loss: 0.6362 - accuracy: 0.6327 - precision: 0.6354 - recall: 0.6714 - val_loss: 0.6408 - val_accuracy: 0.6311 - val_precision: 0.6404 - val_recall: 0.6440\n",
      "Epoch 7/30\n",
      "13375/13375 [==============================] - 449s 34ms/step - loss: 0.6353 - accuracy: 0.6335 - precision: 0.6355 - recall: 0.6746 - val_loss: 0.6357 - val_accuracy: 0.6335 - val_precision: 0.6385 - val_recall: 0.6615\n",
      "Epoch 8/30\n",
      "13375/13375 [==============================] - 448s 34ms/step - loss: 0.6342 - accuracy: 0.6343 - precision: 0.6369 - recall: 0.6725 - val_loss: 0.6449 - val_accuracy: 0.6347 - val_precision: 0.6291 - val_recall: 0.7053\n",
      "Epoch 9/30\n",
      "13375/13375 [==============================] - 495s 37ms/step - loss: 0.6341 - accuracy: 0.6359 - precision: 0.6378 - recall: 0.6764 - val_loss: 0.6388 - val_accuracy: 0.6356 - val_precision: 0.6332 - val_recall: 0.6919\n",
      "Epoch 10/30\n",
      "13375/13375 [==============================] - 538s 40ms/step - loss: 0.6348 - accuracy: 0.6369 - precision: 0.6394 - recall: 0.6749 - val_loss: 0.6636 - val_accuracy: 0.6350 - val_precision: 0.6451 - val_recall: 0.6442\n",
      "Epoch 11/30\n",
      "13375/13375 [==============================] - 494s 37ms/step - loss: 0.6322 - accuracy: 0.6375 - precision: 0.6410 - recall: 0.6716 - val_loss: 0.6425 - val_accuracy: 0.6353 - val_precision: 0.6279 - val_recall: 0.7129\n",
      "Epoch 12/30\n",
      "13375/13375 [==============================] - 508s 38ms/step - loss: 0.6308 - accuracy: 0.6379 - precision: 0.6403 - recall: 0.6760 - val_loss: 0.6392 - val_accuracy: 0.6354 - val_precision: 0.6407 - val_recall: 0.6619\n",
      "Epoch 13/30\n",
      "13375/13375 [==============================] - 498s 37ms/step - loss: 0.6298 - accuracy: 0.6394 - precision: 0.6421 - recall: 0.6761 - val_loss: 0.6607 - val_accuracy: 0.6341 - val_precision: 0.6362 - val_recall: 0.6730\n",
      "Epoch 14/30\n",
      "13375/13375 [==============================] - 523s 39ms/step - loss: 0.6309 - accuracy: 0.6397 - precision: 0.6422 - recall: 0.6766 - val_loss: 0.6373 - val_accuracy: 0.6327 - val_precision: 0.6402 - val_recall: 0.6517\n",
      "Epoch 15/30\n",
      "13375/13375 [==============================] - 480s 36ms/step - loss: 0.6279 - accuracy: 0.6403 - precision: 0.6431 - recall: 0.6761 - val_loss: 0.6570 - val_accuracy: 0.6347 - val_precision: 0.6459 - val_recall: 0.6405\n",
      "Epoch 16/30\n",
      "13375/13375 [==============================] - 449s 34ms/step - loss: 0.6272 - accuracy: 0.6415 - precision: 0.6441 - recall: 0.6777 - val_loss: 0.6402 - val_accuracy: 0.6329 - val_precision: 0.6211 - val_recall: 0.7328\n",
      "Epoch 17/30\n",
      "13375/13375 [==============================] - 451s 34ms/step - loss: 0.6258 - accuracy: 0.6429 - precision: 0.6456 - recall: 0.6782 - val_loss: 0.6697 - val_accuracy: 0.6346 - val_precision: 0.6360 - val_recall: 0.6759\n",
      "Epoch 18/30\n",
      "13375/13375 [==============================] - 450s 34ms/step - loss: 0.6245 - accuracy: 0.6436 - precision: 0.6461 - recall: 0.6793 - val_loss: 0.6446 - val_accuracy: 0.6335 - val_precision: 0.6281 - val_recall: 0.7038\n",
      "Epoch 19/30\n",
      "13375/13375 [==============================] - 452s 34ms/step - loss: 0.6234 - accuracy: 0.6445 - precision: 0.6475 - recall: 0.6785 - val_loss: 0.6991 - val_accuracy: 0.6328 - val_precision: 0.6333 - val_recall: 0.6783\n",
      "Epoch 20/30\n",
      "13375/13375 [==============================] - 451s 34ms/step - loss: 0.6224 - accuracy: 0.6459 - precision: 0.6488 - recall: 0.6796 - val_loss: 0.7860 - val_accuracy: 0.6327 - val_precision: 0.6382 - val_recall: 0.6593\n",
      "Epoch 21/30\n",
      "13375/13375 [==============================] - 448s 34ms/step - loss: 0.6210 - accuracy: 0.6464 - precision: 0.6479 - recall: 0.6849 - val_loss: 0.7695 - val_accuracy: 0.6322 - val_precision: 0.6293 - val_recall: 0.6925\n",
      "Epoch 22/30\n",
      "13375/13375 [==============================] - 448s 34ms/step - loss: 0.6208 - accuracy: 0.6480 - precision: 0.6505 - recall: 0.6827 - val_loss: 0.9410 - val_accuracy: 0.6303 - val_precision: 0.6473 - val_recall: 0.6169\n",
      "Epoch 23/30\n",
      "13375/13375 [==============================] - 450s 34ms/step - loss: 0.6182 - accuracy: 0.6488 - precision: 0.6505 - recall: 0.6860 - val_loss: 1.1350 - val_accuracy: 0.6319 - val_precision: 0.6378 - val_recall: 0.6570\n",
      "Epoch 24/30\n",
      "13375/13375 [==============================] - 453s 34ms/step - loss: 0.6176 - accuracy: 0.6503 - precision: 0.6515 - recall: 0.6888 - val_loss: 1.3260 - val_accuracy: 0.6322 - val_precision: 0.6322 - val_recall: 0.6798\n",
      "Epoch 25/30\n",
      "13375/13375 [==============================] - 447s 33ms/step - loss: 0.6167 - accuracy: 0.6510 - precision: 0.6520 - recall: 0.6903 - val_loss: 2.7855 - val_accuracy: 0.6330 - val_precision: 0.6324 - val_recall: 0.6829\n",
      "Epoch 26/30\n",
      "13375/13375 [==============================] - 448s 34ms/step - loss: 0.6147 - accuracy: 0.6517 - precision: 0.6533 - recall: 0.6883 - val_loss: 2.7257 - val_accuracy: 0.6301 - val_precision: 0.6336 - val_recall: 0.6652\n",
      "Epoch 27/30\n",
      "13375/13375 [==============================] - 452s 34ms/step - loss: 0.6132 - accuracy: 0.6539 - precision: 0.6556 - recall: 0.6896 - val_loss: 3.3840 - val_accuracy: 0.6306 - val_precision: 0.6377 - val_recall: 0.6514\n",
      "Epoch 28/30\n",
      "13375/13375 [==============================] - 453s 34ms/step - loss: 0.6117 - accuracy: 0.6551 - precision: 0.6569 - recall: 0.6900 - val_loss: 4.4048 - val_accuracy: 0.6274 - val_precision: 0.6207 - val_recall: 0.7074\n",
      "Epoch 29/30\n",
      "13375/13375 [==============================] - 448s 34ms/step - loss: 0.6103 - accuracy: 0.6559 - precision: 0.6580 - recall: 0.6897 - val_loss: 1.3660 - val_accuracy: 0.6280 - val_precision: 0.6205 - val_recall: 0.7110\n",
      "Epoch 30/30\n",
      "13375/13375 [==============================] - 451s 34ms/step - loss: 0.6085 - accuracy: 0.6578 - precision: 0.6579 - recall: 0.6977 - val_loss: 3.0073 - val_accuracy: 0.6279 - val_precision: 0.6242 - val_recall: 0.6940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245249f6df0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=30, validation_data=(test_data,test_labels),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/1m_200_2000_200_2022-09-29\\assets\n"
     ]
    }
   ],
   "source": [
    "time = str(datetime.date.today())\n",
    "#model.save('./models/1m_200_2000_200_'+time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('./models/1m_200_2000_200_'+time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344/3344 - 21s - loss: 3.0073 - accuracy: 0.6279 - precision: 0.6242 - recall: 0.6940 - 21s/epoch - 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e8bc2de874a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print('\\nTest accuracy:', test_acc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = loaded_model.evaluate(test_data,  test_labels, verbose=2)\n",
    "\n",
    "#print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55000\n",
       "0    52000\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = np.argmax(probability_model.predict(test_data),axis=1)\n",
    "preds = np.where(model.predict(test_data)>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([45852, 61148], dtype=int64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29021, 22979],\n",
       "       [16831, 38169]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels,preds)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329276803629067"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf[0,0] / (conf[0,0] + conf[1,0])\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6242068424151239"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1] / (conf[1,1] + conf[0,1])\n",
    "TP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d62b7309829161c9ff8c8cb2799597e552c804f98ee796508f623761c3c8a87d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
